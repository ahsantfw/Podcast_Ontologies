# ğŸš€ LangSmith Quick Start Guide

You've added LangSmith configuration to your `.env` file. Follow these steps to start using it!

## Step 1: Verify Setup âœ…

Test that LangSmith is properly configured:

```bash
python test_langsmith.py
```

**Expected Output:**
```
âœ… LangSmith is ENABLED
âœ… Connected! Found X project(s)
âœ… SETUP COMPLETE - LangSmith is ready to use!
```

If you see errors, check:
- `LANGCHAIN_TRACING_V2=true` in `.env`
- `LANGCHAIN_API_KEY` is set correctly
- API key is valid (get from https://smith.langchain.com)

## Step 2: Test Tracing (Optional) ğŸ§ª

The test script will ask if you want to create test traces. This verifies traces are being sent:

```bash
python test_langsmith.py
# When prompted, type 'y' to run trace test
```

Then check https://smith.langchain.com to see the test traces appear!

## Step 3: Run Ingestion with LangSmith ğŸ“Š

Now run your ingestion pipeline. LangSmith will automatically trace everything:

```bash
# Process all transcripts with full observability
python process_with_metrics.py --workspace default

# Or with custom workspace
python process_with_metrics.py --workspace my_workspace
```

**What Gets Traced:**
- âœ… All LLM calls (KG extraction, embeddings)
- âœ… Token usage and costs
- âœ… Latency per operation
- âœ… Full execution traces
- âœ… Errors and retries

**You'll See:**
```
âœ… LangSmith: Enabled (view traces at https://smith.langchain.com)
```

## Step 4: View Traces in LangSmith Dashboard ğŸ”

1. **Go to LangSmith**: https://smith.langchain.com
2. **Select your project**: (from `LANGCHAIN_PROJECT` in `.env`)
3. **View traces**:
   - Real-time traces appear as your code runs
   - Filter by date, tags, metadata
   - Click any trace to see full details

### What You Can Do in the Dashboard:

- **View Cost Breakdown**: See costs per model, per operation
- **Analyze Performance**: Latency, throughput, bottlenecks
- **Debug Issues**: Step through execution, see prompts/responses
- **Compare Runs**: A/B test different configurations
- **Set Alerts**: Get notified of high costs or errors

## Step 5: Explore Features ğŸ¯

### Filter Traces

In LangSmith UI, filter by:
- **Tags**: `ingestion`, `pipeline`, `kg-extraction`, `embeddings`
- **Metadata**: `workspace`, `model`, `batch_size`
- **Date Range**: Last hour, day, week
- **Status**: Success, error, in-progress

### View Cost Analytics

1. Go to **Analytics** tab
2. See:
   - Total cost per day/week/month
   - Cost per model (GPT-4o, embeddings)
   - Cost per operation type
   - Cost trends over time

### Debug a Specific Run

1. Find a trace in the list
2. Click to open
3. See:
   - Full execution tree
   - Inputs/outputs at each step
   - Token usage per call
   - Latency breakdown
   - Errors (if any)

## Troubleshooting ğŸ”§

### Traces Not Appearing?

1. **Check environment variables**:
   ```bash
   echo $LANGCHAIN_TRACING_V2  # Should be "true"
   echo $LANGCHAIN_API_KEY     # Should have your key
   ```

2. **Verify API key**:
   - Go to https://smith.langchain.com
   - Settings â†’ API Keys
   - Make sure key is active

3. **Check project name**:
   ```bash
   echo $LANGCHAIN_PROJECT  # Should match your project
   ```

### High Overhead?

- LangSmith has minimal overhead (~1-2ms per trace)
- For very high volume, consider sampling
- Traces are sent asynchronously (non-blocking)

### Free Tier Limits?

- Free tier: 1,000 traces/month
- Paid plans start at $39/month
- Self-hosted option available

## Next Steps ğŸ¯

1. âœ… **Verify setup** - Run `python test_langsmith.py`
2. âœ… **Run ingestion** - Process your transcripts
3. âœ… **View traces** - Check LangSmith dashboard
4. âœ… **Analyze costs** - Review cost breakdowns
5. âœ… **Optimize** - Use insights to improve pipeline

## Example: What a Trace Looks Like

When you run ingestion, you'll see traces like:

```
full_ingestion (chain)
â”œâ”€â”€ load_transcripts (tool)
â”œâ”€â”€ chunk_documents (tool)
â”œâ”€â”€ extract_kg (chain)
â”‚   â”œâ”€â”€ extract_batch_1 (llm) - GPT-4o
â”‚   â”‚   â”œâ”€â”€ Input: 2,000 tokens
â”‚   â”‚   â”œâ”€â”€ Output: 400 tokens
â”‚   â”‚   â””â”€â”€ Cost: $0.005
â”‚   â”œâ”€â”€ extract_batch_2 (llm) - GPT-4o
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ingest_qdrant (chain)
â”‚   â”œâ”€â”€ embed_batch_1 (llm) - text-embedding-3-large
â”‚   â”‚   â”œâ”€â”€ Input: 1,000 tokens
â”‚   â”‚   â””â”€â”€ Cost: $0.00013
â”‚   â””â”€â”€ ...
â””â”€â”€ Total Cost: $X.XX
```

## Tips ğŸ’¡

1. **Tag Everything**: Use tags for easy filtering (`workspace`, `operation`, `model`)
2. **Add Metadata**: Include context (episode_id, batch_size, etc.)
3. **Regular Reviews**: Check traces weekly to find optimizations
4. **Set Alerts**: Configure alerts for high costs or errors
5. **Compare Versions**: Tag runs with model/prompt versions

## Resources ğŸ“š

- **LangSmith Docs**: https://docs.smith.langchain.com
- **Dashboard**: https://smith.langchain.com
- **Setup Guide**: See `LANGSMITH_SETUP.md` for detailed docs

---

**Ready to go?** Run `python test_langsmith.py` to verify everything works! ğŸš€

