[00:00:08.570] - Speaker 1
Tetragrammatin.

[00:00:13.010] - Speaker 2
Tetragrammaton.

[00:00:17.730] - Speaker 1
Tetragrammatin.

[00:00:22.530] - Speaker 2
You know, every year there are some number of thousands very bright people, many of them young, some of them older and more experienced, who come up with ideas for new tech products and new tech companies. And they, and typically a small group of their friends get together and they decide to kind of throw the harpoon and start a company and try to build a product. They need some level of money, and then they need some level of basically support, institutional support. So they're often young, less experienced. They often have not been through the journey before. They're going to need to gather a lot of resources along the way. They're going to need to hire a lot of people. Basically, they'll have big opportunities they want to pursue. They'll have problems that will pop up. Even the great successful companies, from the outside, they look like everything is great. On the inside, they're typically some form of rolling disaster. There's always something going wrong. So basically, they're sort of at some point looking for partners who can help them do that. And so venture capital kind of bundles the money kind of with the help, and then a couple of probably misnomers to it.

[00:01:24.040] - Speaker 2
One is you would think, like, the day job is saying yes to new companies. It's actually saying no. We pass on almost everything. So the sort of a black humor joke is our day job is crushing entrepreneurs hopes and dreams. But that said, the good ones view that as a challenge. Right? And they view us as kind of the initial test to see if they'll be able to clear the bar, because if they can clear the bar with us, then they'll have a good chance of being able to clear the bar with future recruits or customers or other kinds of people. They'll need to say yes to them in the future. And so, yeah, we sort of present that. We sort of provide the initial gate. Another kind of misnomer would be that tech kind of has this reputation for being very fast moving. Right. And so things, technology is developing quickly. It actually turns out we're one of the sort of slowest investors. Venture capital is one of the slowest kinds of sort of investment money in the world, because to build any kind of grade company is anything that you're going to remember that's going to last.

[00:02:16.320] - Speaker 2
It's a 1020 year project, kind of at the minimum. And so when we invest, we invest, assuming we're going to be in for at least a decade. And so we're just there for a very long time every day, helping them work through things. Basically, we never press to kind of get our money back. We're always trying to kind of help them build more value. When you're running a venture capital firm, you're basically running a family of funds that run across basically 20 years. Right. So you're sort of raising money on a new fund. You've got an older fund that has companies that are three years old. You've got an older fund that's got companies that are eight years old, and so forth. And so you kind of have this thing where you're raising money that, it's like planting trees. You're planting trees, you're raising money on things that won't pay out for a decade. But if you've been in the business for a while, you have things ultimately that are succeeding from a decade ago, and you just kind of keep the process rolling.

[00:03:01.910] - Speaker 1
Do you see the same mistakes that founders make across the board, or are there different mistakes all the time?

[00:03:10.650] - Speaker 2
The cliche success. All happy companies are the same. All unhappy companies have a unique story, for sure. There are patterns of the mistakes. There are lots of different mistakes to be made over time, have made them all.

[00:03:21.870] - Speaker 1
What are the obvious ones?

[00:03:24.350] - Speaker 2
The biggest category by far is internal dissension on the team. Right. So these things are never solo acts. It's always a team. And this will not come as a shock to you. It turns out when you have a team of people, even if they start out getting along really well, even if they consider themselves kind of brothers and sisters, under the pressure of success, also.

[00:03:42.820] - Speaker 1
Of success, particularly in success, you see people come apart.

[00:03:46.810] - Speaker 2
Exactly. Right. Money. And put it. Money and fame basically reveal the true person in a lot of ways. Right. And so, yes, there's that. People lose their minds also, just like it's high stress. Right. And so things go wrong. It's very easy to develop resentments. It's very easy because these founders are under so much pressure. And so it's very easy to develop resentments of, like, I can't believe you're hogging the limelight. The other one's like, well, I can't believe you're not pulling your weight. And then they kind of get in this kind of downward spiral.

[00:04:12.900] - Speaker 1
Same as a rock band.

[00:04:13.880] - Speaker 2
Yeah, exactly. Right. And so it's like, most of it sort of my big conclusion is, like, it's basically a tech startup might or might not work. And whether it fundamentally, whether it works or not is basically a function of, does it build something that people want? And can I kind of build a business around.

[00:04:25.670] - Speaker 1
Is it as simple as that? If they make something people want, it's probably going to be okay?

[00:04:29.530] - Speaker 2
Well, if the team holds together, right? That's the thing. There's an old venture capital adage, which is more companies die from suicide than homicide. So, look, if it's not working, then the team is going to really be pressing each other hard, and that can easily go sideways. If it does work, the team can blow up for the reasons we discussed. This is what the speech we always kind of give the founders is like, look, if you guys can kind of cohere together and stay basically as an integrated team and group and trust each other through the hard times, there's almost always a way through the specific difficult thing of the moment. There's very few kind of non recoverable mistakes, but you have to really stay together. And then basically what you see with a lot of these companies is at some point, if there's a crack on the team, that crack then magnifies out, and ultimately, in some cases, can actually destroy the company. And I would say most of it's that. Now, this is a speech. I was just with these two young founders last night who are all fired up for their new AI company, and they sort of were asking about the failure cases, and I was like, yeah, the most likely failure case is you guys are going to turn on each other, right.

[00:05:30.560] - Speaker 2
And of course, legitimately, they get the stricken look on their face. Right? And then immediately followed by, well, of course that's not going to happen to us. And it's like, well, yeah, but also.

[00:05:39.700] - Speaker 1
Half the marriages end in divorce. It's the same.

[00:05:43.100] - Speaker 2
Exactly. It's actually marriage. I think there's an argument to be made. I'm not like a therapy person, but I think there's an argument to be made that people should think about the partnerships, the way that business partnerships, the way they think about marriages. I think there's an argument to be made that marriage counseling might be helpful. Some sort of, let's say, intentional process of developing trust and communication. That said, look, when these things get started, it's like a marriage. They're so euphoric and excited, and they feel so tightly bonded that they don't want to ever imagine that could ever actually happen. And so when it does happen, it usually comes as an enormous shock. And that's probably the single biggest company killer, is when that happens.

[00:06:15.960] - Speaker 1
Would you say the primary thing people are coming to you for is money, or is there more to the picture?

[00:06:21.280] - Speaker 2
Yeah. So I think it's more than that. So I just tell you what we always wanted. So my partner Ben and I always wanted, when we were starting, we started our own companies for 15 years before we started a venture firm to back other people's companies. And basically, it's just like, look, we knew what we wanted to build. Like, we knew what the product was, we knew what, vision wise, we had it. But it's just all of the mechanics. And maybe here's the difference, maybe, versus friends like you working in the entertainment business is if a band comes together, people do a movie, maybe they do an album, maybe they do a movie, maybe they do a sequel, maybe they don't, right? Whereas with tech companies, it's more like for them to work, they really have to compound over, like I said, over like a decade or two decades. And so there's no, well, sometimes they'll do it for two years, they'll sell the company. But that's not the big success case. Those are kind of small scale successes, usually like, to build something important and valuable, it has to be a decade or two decades.

[00:07:10.820] - Speaker 2
And so they have to really learn how to build an institution. And to do that, typically they need a level of sort of, I would say, knowledge, support, expertise, access to resources. Another metaphor I use a lot is that building a tech company, it's like a snowball rolling down a hill. If it's working well, it's growing as it rolls. The way a snowball kind of accretes snow and gets bigger. A startup, in theory, is accreting resources, right? And so it's kind of pulling people in. It's pulling in more engineers, product designers. It's pulling in the right kinds of executives. It needs to build its team. It's pulling in customers, it's pulling in partnerships, it's pulling in press attention, it's building a brand. It's sort of, sort of drawing all these resources to itself. And of course, there's a competition among all the different startups of that same generation to get all those resources. And so they're fighting with the other snowballs as they roll down the hill for all that stuff. And so over time, it has just turned out that it's very helpful to most of those teams. If they've got somebody, if they've got something of the form of a venture capital firm, some set of people behind them who have done it before, know how to do know.

[00:08:12.720] - Speaker 2
We don't run the know. This is not like private equity. We don't come in and run the show. But who's their first call basically, when something goes wrong or when they need something, a lot of what we do is close candidates. They'll be talking to some engineer, they'll be in a shootout with Google and then three other startups to hire an engineer. And so they'll roll me in and I'll spend an hour with the person. Basically, part of it is just like, help them help the candidate get over the hump. But also one of the tricks you can do when you have a big venture capital firm like ours is you can say to candidate, you might be like, well, look, the candidate might be thinking, I could go to Google. And I just have like, I know everybody's going to think I made a great decision in my career, even if it doesn't go well, I go Google on my resume. If I go to the startup, who's even going to care what I did if the startup doesn't work? Like, am I going to be stranded if the startup fails? And so one of the things we get to do is we get to say, look, if it doesn't work, we will know you and you'll be a member of our family as well.

[00:09:02.170] - Speaker 2
And we have hundreds of other companies, and we know all the big, and we will help make sure that your career prospers even in the wake of a failure. And we will vouch for you kind of through that. And so there's like 100 different versions of that. That's how we win. We don't win on price. We win basically on being able to be their partner.

[00:09:18.540] - Speaker 1
Did you have experience with vcs from the founder side?

[00:09:22.260] - Speaker 2
Yeah, very much.

[00:09:23.430] - Speaker 1
Tell me, give me an example. What was that like?

[00:09:25.970] - Speaker 2
Yeah, so look, I had really good experiences. I had really good experiences. I raised money in 1995. My partner, Jim Clark and I at the time raised money in actually 94 from a firm called Kleiner Perkins, which was at the time considered kind of the top venture capital firm. I worked with them for five years. Ben and I started a company in 99. We raised money from benchmark, which at the time was one of the top firms. We worked with them for a long time, and then Ben and I had also been angel investors. And so we had invested in, probably by the time we started the firm, over 100 startups. And we were kind of from the side, kind of working with a lot of the founders. And a lot of the things we were working with the founder on was navigating the venture landscape, helping them meet the right firms, and then actually helping to kind of, we were actually the marriage counselors a lot of the time. So we were kind of helping them kind of unwind when their relationship with their vcs would get all screwed up. We would kind of help them kind of unwind that.

[00:10:13.030] - Speaker 2
And so we became expert customer. And then at some point, we're like, okay, we could probably do this.

[00:10:22.150] - Speaker 1
It seems like a better position to be in coming from that. Having that experience has to make you better at being on the other side of the table.

[00:10:29.820] - Speaker 2
Yeah. So our argument is very much that. Our argument is we have been you. We have been through everything you've been through. We have made every mistake that you're going to make. We have figured out ways to get through all those mistakes. Right. And then we deeply understand you. We understand what you're trying to do, and we're going to sympathize with you along the way. There is a counterargument to that that I think about a lot. And it's the argument that vcs who have not started companies use against us. And basically the argument goes that if you're a former operator founder like we are, you will tend to get emotionally entangled with the companies, and you'll become not objective and not clinical. And at some point, when you're investing money and even when you're actually advising companies, at some point you need to get clinical. There are certain moments in time where you need to actually recognize the truth and tell the truth, both to yourselves and to the companies. Right. And to everybody else. And so the argument goes that basically you might be a better founder, you might actually be a worse investor.

[00:11:24.190] - Speaker 2
As a result of the inability to get clinical, we try to offset that by kind of being very conscious of that and trying to kind of retain our critical faculties. We do, like, internal portfolio reviews every quarter. And so we kind of force ourselves to basically tell the truth about everything. Look, having said that, if the failure cases, we get emotionally entangled with somebody working hard to realize their dream over a decade, fair enough. I think it's much better to err on that side and get the payoff of that, which is like, we're really there. We're really deeply there. We don't quit. We don't walk away. We care tremendously. We have all of the added motivation that comes from caring tremendously.

[00:12:00.650] - Speaker 1
Pick an example of a story of a company that you've either invested in or been part of a success story, and walk me through all of the stages of what happens, the ups and downs along the way. A case study.

[00:12:16.410] - Speaker 2
Yeah. I'm going to use code names for the companies because I don't want to pick on or speak for the individual companies. Look, I have a company right now. I'm going to call just a company. S. And it was the easy one. Like, it was two founders who had started a previous company together. Their previous company went through a lot of ups and downs. It actually hit the financial crisis really hard in 2008 and almost blew up. And they had to make all these changes, and then they ended up selling it to a big company. And then they basically were like, all right, we want to do the new thing. I don't know. It's like watching Babe Ruth or something point to the place in the outfield where he's going to hit the home run, and they just hit the ground running. They've had issues along the way, but it's mostly been this incredibly smooth. It's just like this well oiled machine. They've just hit a huge kind of revenue milestone. They're increasingly important in their industry. Every once in a while, you get one that goes that well. A lot of what happens is just like in the beginning, everything is a dream.

[00:13:12.950] - Speaker 2
It's a clean sheet of paper. It's this incredible moment of sort of, what do they call it? It's like a liminal moment where you can basically design your dream, and your dream is the product you've always wanted to build, and your dream is the company you've always wanted to have. And you kind of think of those in parallel, and you bring in all the smart people, you know, and it just seems like everything's going to be great. You kind of expect it's going to be hard, but you're all fired up. And then basically what happens is reality just punches you in the face over and over and over again. And generally that takes the mode of basically people telling you no, right? And so vcs tell you no, they won't fund you, employees tell you no, they won't join your company, customers tell you no, they won't buy your product, and kind of all the way through. And then disaster strikes every month or two in one form or another. We talk a lot about the emotional treadmill, which is sort of the founder sort of psychology. My famous line on that was it alternates between euphoria and terror, and then it turns out that lack of sleep enhances both of those.

[00:14:08.590] - Speaker 2
Right? And so it's the four in the morning. Okay, well, there's another thing which is related to this, which is the founders have to put on a brave face, so they have to always basically act like everything's going great because otherwise it'll shake confidence, right. And they'll lose team members and they won't be able to raise money or whatever. So they always kind of have to act like it's going really well. And in fact, going to a party with a lot of founders is really funny watching them because everybody's asking each other, well, how's it going? And everybody's got this very four first grin in their face and they're like, oh, everything's going great, and everybody's just dying inside, right. But nobody can say it, right? And so I always think about, like, it's the four in the morning kind of thing where you're staring at the ceiling, right? And yesterday it felt like you had the tiger by the tail, and today it feels like it's all going to fall apart and just like, oh, my God, right? And then the other thing I find is that doesn't really ever moderate. Like, if you talk to a lot of people who are still founders running their companies ten or 20 years later, a lot of their life is every morning they open up their email inbox and it's just like a descent into hell, right?

[00:15:06.610] - Speaker 2
It's just like one person after another with an issue and a complaint and a problem, and I quit, and fuck you, and just on and on and on. And they got to get up in the morning and put on the hoodie and head in there and just confront all these things head on. Some of them love to do that and battle their way through every step. Some of them check out, some of them just get a few years into it and they're like, I just hate living this way. I'm becoming unhealthy. People develop, people develop alcohol problems, drug problems, all these things. What's probably striking about this is like, wow, this sounds like it's like, mostly psychological, right? And it's like, yeah, I think it's mostly psychological.

[00:15:39.970] - Speaker 1
Well, it's pressure. It's a tremendous amount of stress.

[00:15:42.820] - Speaker 2
Yeah, that's right.

[00:15:44.050] - Speaker 1
How small is the world of vcs and founders, like, altogether? Is it hundreds of people? Do you know everybody? Is it thousands of people? Is it hundreds of thousands?

[00:15:55.810] - Speaker 2
Yeah. So say the following. So one is it doesn't really ever stabilize and so many other industries. And I think music was probably like this for a long time. I don't know if it still is, but at some point in a lot of businesses, basically, things stabilize and you just have, like a certain number of record labels or a certain number of movie studios at some point. And then every once in a while.

[00:16:12.530] - Speaker 1
There'S, like, small changes.

[00:16:14.000] - Speaker 2
This is what's evolution. They call it punctuated equilibrium, right? And so things are kind of cruising along, and then every once in a while, there's, like, a disruptive moment. So somebody develops hip hop or something and everything changes. But you can kind of count those over time, right? And those are, like, specific moments people write books about, and they're really big deals. Or every once in a while, like, a movie studio will go under. But it's actually very rare. Warner Brothers is still in business 100 years later. Tech never stabilizes like that. It always kind of looks like it's stabilized. And then basically there's some earthquake in the form of basically disruptive technology change. And then basically everything gets kind of tossed up in the air and kind of redone. These platform shifts happen actually quite regularly. It's like every five years. And so it's like, for computers, it was mainframe to pcs to mobile, right? And then for Internet, it was one point no Internet, and then Internet, and then cloud, and then social. Now there's this AI thing, right? And so every time you have one of these kind of earthquakes, it sort of recalibrates everything.

[00:17:07.750] - Speaker 2
It's like the meteor strike hits and the dinosaurs die and the burrs take off kind of thing. So because that's sort of a more common thing in our world, there's just more of this pattern of. And then the new thing is often led by people who were not important in the previous wave, right, because a lot of its kids, a lot of its kids who kind of grew up with whatever the new thing is, and they just have a different take on how the world should look. I was an example of that. Yeah. So basically, there's actually a lot of turnover. There are venture firms that are 50 years old, but they're on generation five or six of partners, and a lot of their peers from when they were younger no longer exist. Whether they're even the same firm anymore is like an open question. The company is going to last for a long time. Generally. At some point, the companies basically become. At some point, Elvis leaves the building. Like, at some point, the sort of innovation spark leaves a company. Right? Like when the founders basically, at some point, punch out or retire.

[00:17:59.170] - Speaker 2
At some point, even the most innovative company just kind of becomes a big, normal, boring company. So it's still in business. I would say it's a little bit like a neutron bomb hits these things or something. It's like the building is still there. There's still people, the parking lot is still full of cars, it still has customers, but it hasn't invented a new product in a decade. Right? And so what even is that? And by the way, it has like 100 times the number of employees it had when it used to develop products all time. And so what's happened there? And so those companies kind of, they're still important from a business standpoint, but they're no longer vital. They don't do the new things, and that's when the new startups show up anyway. So back to your question is like, yeah, it's basically sort of continuous turnover of people. Everybody is highly aware that a 22 year old can show up at any moment and upend the entire thing. And that has happened repeatedly. So people are kind of very open to that possibility. It's still jarring when it happens because it's like, number one, the changes seem so weird in the beginning, and then number two, like, 22 year olds seem really young.

[00:18:52.650] - Speaker 1
What was the last one of those?

[00:18:54.000] - Speaker 2
It's hard to process that. I mean, we're going through it right now with AI. That's the big one right now, this one's not so much 22 year olds. This one's more people who have been toiling in research labs for decades without really anything to show for it, and their stuff just started to work. And so you actually have a lot of scientists who never thought they would be in business all of a sudden are like basically top entrepreneurs, and they're kind of emerging, blinking out of basement labs into the real world, kind of trying to now build companies. So that's happening. But the classic recent one, social networking. Mark Zuckerberg shows up. He's 22. We had a party, actually, I'm on his board, and we had a party when he finally became old enough to rent a car. Right. It'd be a big deal on business trips. Right. Amazing. As the CEO of this incredible new company. So, yeah, there's a lot of turnover. I would say it's. And then I say the other thing is, and this is the uncomfortable part of the topic, I think, is it's an elite occupation. Like, it really is.

[00:19:48.140] - Speaker 1
It's still a small pool, even though the characters are changing. It's a small pool.

[00:19:52.420] - Speaker 2
It's a small pool. And every once in a while, you get somebody who just comes completely out of left field, who went to some college you've never heard of and came from some random country and doesn't have connectivity, and they just show up and they're just really amazing.

[00:20:02.130] - Speaker 1
Well, that was you.

[00:20:03.730] - Speaker 2
That was me? Yes. There's not a lot. Yes. But I would say that the more standard pattern is there's a small number of universities, Stanford, MIT, Berkeley, a few others. There's a small number of kind of important companies at any point in time where young people are getting trained by working there and kind of gaining the skills. It's actually like music. There are scenes, right? There are social scenes. There's these kind of loops of people who all know each other are kind of coming up. Whenever I read interviews with either comedians or musicians, it always turns out they were with all of the other people of their cohort at that time. And what they all kind of had in common is nobody was taking any of them seriously. Right. And so that same thing happens. There's also a small number of geographic locations. San Francisco Bay Area just ends up being the center of the world for a lot of this. Why is San Francisco? And when I say San Francisco, there's San Francisco, the city which has its own idiosyncrasies, and then there's just the Bay Area generally. So a lot of it's just office parks.

[00:21:01.230] - Speaker 2
Well, so practically, it's where Stanford and Berkeley are, and it's where Facebook and Google and all these other companies are. And so it just kind of is already ground zero. And so there's a natural kind of continuation thing that takes place. And then there's also a long history to it, which is Silicon Valley really started in the 1920s, 1930s, even with technologies before the computer. So it's running on like 100 years of what you might call a network effect, where basically meaning the next really bright person who's technical, technologically oriented is more likely to come to the place where all the other smart people are than to go anywhere else. So there's like a positive feedback loop that kind of just keeps spinning. And then, quite honestly, I think there's just something really. I mean, look, California has its problems, and they are profound, but there's something magical about California. There has been something magical about California that predates the entertainment industry, that predates the tech industry, and it's basically the California is the frontier. And the same mentality that led to the original settlement. California was sort of the furthest thing to the west that was settled.

[00:21:58.950] - Speaker 2
It was ungoverned for a long time. You had the gold rush, the wild west. Wild west. And then what happened was there was this just like, selection process where if you were oriented around status and respect, you wanted to succeed on the east coast in New York and Boston. And if you wanted to go carve your own path and create something new. You went basically as far away from the east as you could get. And that's basically where we sit right now. You could call it like creative people experiment, right? They blaze new trails in every way, including how you live your life. California is famously the home of thousands of cults have been developed here. I think it's actually no accident that California is sort of. We call it sort of the stack. California builds the technology of dreams and then Hollywood and the entertainment business actually makes the dreams, right? And so it's like this sort of integrated dream factory. Is it ever really quite real? Los Angeles is like famously a fake city, right? It was just like a desert. And then they just basically. It was theranosis cities when it first got started.

[00:22:59.370] - Speaker 2
And they ran newspaper ads in east coast cities with drawings of palm trees. Know this lush paradise. And then people would buy plots of land and they come out here and it was just desert. And then they famously had to go get the water from the Central Valley.

[00:23:08.750] - Speaker 1
And that led to lion palm trees.

[00:23:11.250] - Speaker 2
Yeah. And it turns out the palm trees are imports. It turns out palm trees. This is actually one of my big breakthrough moments in understanding California, which is the palm trees are not like, it's just this made up, basically the most iconic kind of thing for California, basically is just like a made up import. And so there's like an artificial american idea, though. Yeah, very much, yeah. Here we sit in Shangri La, right? Like paradise. Right. You know, and, you know, the weather, like the. If you have a fundamentally, you know, of where you can know, wouldn't it be nice to live someplace where it's like 70 and sunny every day? Wouldn't that be awesome? It's the thing the Bay area and La kind of have in common, which is kind of the spirit of adventure. The original movie industry people came out here for two reasons. One is they were fleeing Edison's patent enforcers. He had patents on movie recording equipment, projectors, and so he would send in the Pickertons to break up your studio if you weren't paying him his patent fees. So they came 3000 miles away to get out of the orbit of eastern power.

[00:24:06.900] - Speaker 2
And then they also came here for the weather because they could film year round. And that spirit exists. And it's actually an exciting time for that because for a long time, the sort of north and South California were sort of pretty starkly divided and you didn't have a lot of crossover. I mean, a lot of your predecessors in music just never had any viewed technology as a threat, if they even thought about it at all, and had very little interest in what was happening, and quite frankly, vice versa. And there's just a lot more crossover. It turns out the valley is more creative than we thought. It turns out LA, actually, there's old people down here who are actually quite interested in tech and have done a lot in tech, and so there's real magic happening. Look, having said that, California also has all the downsides, and Silicon Valley also has all the downsides of a place where basically people are making up dreams from. There's. There are dystopian elements to. Right, like, is San Francisco a real city? Is always kind of an interesting question because they no longer arrest criminals.

[00:24:59.130] - Speaker 1
How's it working?

[00:25:00.270] - Speaker 2
Right, like, you might just get, like, stabbed and killed walking down the street. But a friend of mine got a job working for actually OpenAI, and he moved to be close to the office, and he got an apartment a block away. And they're in the mission of San Francisco, which is sort of famously the hub of AI, but also just like, incredibly violent, and basically laws aren't enforced. And he said, oh, I love living near the office. He's like, I wake up in the morning, I go to stairs, so I'm block away from the office. The key is I run at full speed, as fast as I can from my apartment to the office. And then at night, I run as fast as I can because I'm trying to not get basically stabbed or killed on the way in. And so it's got both of those. The drug thing has always been a big deal. Hallucinogens are like a big thing up north, and it's the good and the bad. They're opening people's consciousness and horizons. And there's a cultural creativity flowering thing that's happening just like it happened in the. But there's also the downside, which is you see people whose lives are getting wrecked by drugs, and so it's also got that side of it, and so it's got this very organic.

[00:25:56.950] - Speaker 2
It's just like this perpetual cycle of cultural creation, people designing their lives, and then people building these products and these experiences that people all over the world kind of consider to be the best that there are. So it's a special place.

[00:26:13.130] - Speaker 1
It felt like in the early days of the valley. And when I say the early days, I mean seven years ago, the idea of move fast break things, disruptor awards were really good. You know, Apple had the think different campaign, and something seems to have changed.

[00:26:33.650] - Speaker 2
Let me ask you. What do you think has changed?

[00:26:35.150] - Speaker 1
I don't know. I don't understand it because it seemed like the whole tech revolution was about you could finally be yourself, you could learn what you want on the Internet. You didn't have to get what was fed to you. I remember at one point in time, Twitter was called the free speech wing of the free speech party.

[00:26:54.700] - Speaker 2
That's right.

[00:26:55.990] - Speaker 1
So what changed?

[00:26:57.180] - Speaker 2
What changed?

[00:26:57.870] - Speaker 1
What changed?

[00:26:59.210] - Speaker 2
So let me start with. I actually think a lot of that is still there, and it's not there as much in the big companies, but there is still an anarchic spirit in the startups. And so we meet with people every day who basically are just like, yeah, screw it, I'm going to break a lot of glass, right? I'm going to just do something brand.

[00:27:14.370] - Speaker 1
New and people, isn't that necessary to make new things?

[00:27:17.100] - Speaker 2
I believe so, yes.

[00:27:18.030] - Speaker 1
I think it seems like I believe it is.

[00:27:19.650] - Speaker 2
Let me say, I'm very much in favor of it, and we could talk about why that is. But, yeah, it's obvious that's how you do new things. Like, you have to look, the past will crush you, right, if you let it. But most cultures throughout time, and most cultures in the world today, their thoughts are dominated by the past, right? And there's a good to that, right. Which is they have cultural, they have continuity, right. They venerate their ancestors. Literally, the natural form of human society is like, literally ancestor worship. Right. Look, there's a lot to that because your ancestors learned a lot, and they try to pass it on to you through these kind of cultural transmission. Things started with epic poetry and then made its way through to kind of all the books and stories that we have today about people in the past. But most cultures are just completely dominated by the past, and they just don't do new things. And anybody who tries to do new things, there's this thing called tall poppy syndrome. The tall poppy gets chopped off, right? And there's tall poppy syndrome in the west, there's tall, tall poppy syndrome in the east.

[00:28:11.370] - Speaker 2
It's like this very natural kind of tribal thing. And so anybody who's really going to do something new is going to upset the apple cart, and it's going to make people upset. And then I would say technology is maybe even the most kind of advanced version of that, or the most dramatic version, which is like a transgressive piece of content, like a transgressive song or movie can really make people mad by suggesting that there's a different way to live and that obviously can have a big effect. But tech does something, I think, even more than that, which is when something disruptive in tech changes, it doesn't just change tech, it also changes the sort of order of status and hierarchy of people. Right. This is sort of the thing. So why does the media hate tech so much? And there's a lot of potential explanations for that. And one of them is just like, we cut the legs off from under the media business. We basically obliterated for newspapers. We obliterated, basically, most of their advertising revenue because most of that, people used to advertise in newspapers. Now they just advertise online. And so there's like a big reordering.

[00:29:04.600] - Speaker 2
Well, actually, in music that's happened. Right. Napster file sharing cut the legs off from under the economic structure of the music industry. That caused a massive turnover in who was running the music companies. And now there's a new generation of people who have figured out streaming and digital distribution. And so there's been a complete reordering of status that's come from that. So I think that's a lot of that. Yes. Look, I think you have to do that. I think there's a couple of other just broader things that have happened. This one I'll kind of pin on us, which is just like, because the dog has caught the bus. A lot of us who've been in tech for a long time, it was always like, wow, what we're doing is actually really valuable and important, and people don't understand it, and we have to tell them how valuable and important it is. And now it's like, oh, they actually get it. And now they're mad, right? We won, right? The dog has got the bus. Everybody gets it now. Everybody gets the tech is powerful and important, and now they're really upset about it right now.

[00:29:53.330] - Speaker 1
They want to control it.

[00:29:54.050] - Speaker 2
And now they want to control it. Exactly. The dog has got the bus. It turns out the bus has its own opinions on where things should go. The dog is going to get dragged behind the bus. And so there is some of that, look, the other thing that's happened that you know well, but the other thing that's happened is just, look, the world, I think, really changed in 2016 and why and how, and how much of it was one guy and how much of it's a global phenomenon. We sit here, sitting here today, a very Trump like figure just won in the Netherlands. And this kind of huge surprise, a Trump like figure just won in Argentina, which is this kind of huge surprise. But the world, as I experienced it in the United States, in the Silicon Valley. It really changed in 2016, and a lot of people really got psychologically altered, shattered, broken, reformed, kind of through that. And I bring it up just because tech got pulled into that shift, just like everything else has gotten pulled into that shift. And that's why I tell our founders a lot of the time who try to grapple with this stuff is just like, look, what we're doing is valuable and important, but we're not the bus.

[00:30:51.010] - Speaker 2
We are the dog. Society writ large has energy and momentum of its own, and we are wrapped up in it just like everybody else. We are changing it in some ways, but also we are part of it, and we're getting kind of dragged along with whatever the prevailing trends are. And so tech has become politicized, and I would say socially energized in a way that it never had been. I don't know, maybe this is a big difference between this and LA, which is maybe in music and movies, you could say that music and movies have always been intertwined with politics, probably going back forever, but for sure going back to the 60s, right? Kind of very deeply intertwined. And music may have actually caused sort of political and social change in the. But it was also reacting to it, right. It's like a feedback loop. And I think in tech for a long time, we didn't have that. We were building, like, tools. We were building fun tools that people could play with and use. But when they would get engaged in politics or whatever, they would put down our stuff, and then they would go out on the street or go on tv or do whatever they would do.

[00:31:48.470] - Speaker 2
And now tech is integral to how society works.

[00:31:50.840] - Speaker 1
But even beyond tech, there was a time when big companies were focused on making the best product they could and having the best bottom line they could. And that was all they were focused on. They were focused on the business that they were running. And it seems like somewhere along the way, the idea changed, where now corporations whose obligation to their shareholders is to do what I just said, now feel like they have some moral imperative. How did that happen?

[00:32:22.930] - Speaker 2
Yeah. So, look, I should start by saying, for people who haven't really thought about this hard, you didn't do this. But there's a misnomer that people apply to companies, which is they'll say, there's usually criticism. They'll say companies are only focused on their shareholders and they're only focused on making money. People sometimes say they're legally required to optimize profits no matter what. Right. And this is why they say companies are sort of going to be sort of intrinsically morally neutral or even evil, because if it makes sense to pollute or if it makes sense to have horrible policies or whatever to build products that deliberately break so that people have to buy the new thing next year, they're going to do all these evil things because they're optimizing for profits. It actually turns out there's actually no legal requirement for companies to purely optimize for profit. In fact, quite the opposite. You're supposed to optimize for kind of a long term value, and management has a broad latitude to be able to kind of decide whether to engage in social issues, whether to have different kinds of policies inside the company. You're perfectly protected legally as an executive of a company.

[00:33:17.550] - Speaker 2
If you trade off short term profits for some longer term, just, say brand value. Like, even though doing this thing would call, we were thinking of starting a new whaling division and we were going to kill a bunch of whales and sell their meat. We could make money doing that, but we're going to decide not to do that because it would impair our brand. Like, as a corporate executive, you're completely legally covered. Nobody will ever, will ever question that. So corporate executives have always had a fair amount of latitude in terms of how they want to steer their companies. Look, for a long time, one is just like, look, business people were just focused on business. But the other thing that happened was the received wisdom that you got when you were trained up in corporate America. I would say between the. Around 2016 and the way I was trained up was you actually don't want to get involved in political and social issues because of the backlash. Like, you're going to make people mad, right? You're going to summon the demon of you become involved in politics or social change. Politics and social change or become involved in you.

[00:34:10.640] - Speaker 2
And so you're sort of inviting a level of backlash that very well might destroy you.

[00:34:14.920] - Speaker 1
That was something Michael Jordan famously said early on when they asked him about politics. He said, I want everyone to buy my sneakers. That was his answer about what his.

[00:34:24.790] - Speaker 2
Political affiliations and, you know, is that a capitalist statement? In part. But is that also a social and political and moral statement, which is, look, I don't want to be divisive figure, right? I don't want to have some kids love me and other kids hate me because I'm on the wrong side of some divide, right? So to your point, I think that was very common. Look, I don't know. This vortex opened up and a very large number of executives got felt very guilty about some set of social and political things. There was tremendous peer pressure that developed to be able to stand up on things. Employee bases changed. The millennials in particular showed up in the workforce with a lot more sort of demands on their employers. I mean, even my socially activated older friends, who in business even they are shocked that the young employees show up kind of so fired up and so demanding that the companies take all these different positions. And so that happened. And then, look, I think some people think they can differentiate. I think some companies have deliberately decided that they'd rather have half the market love them and half the market hate them than have nobody care.

[00:35:27.560] - Speaker 2
And so I think maybe that's, you might say, hypothetically at Nike, for example, actually might be quite happy if liberals buy twice as many shoes and conservatives don't buy these shoes. And maybe that works. And then quite honestly, I think people are drunk. I think they're drunk on sanctimony and they're drunk on politics, and they're drunk on feeling powerful and they're drunk on grandstanding. And I think it's like a chemical, it's like a chemical thing. It's a drug. And it's very easy to get hooked on that drug. It feels great, right? And then people on your side are, like, praising you and talking about how wonderful you are. And you even say it. Also probably to some extent, it feels good to be hated, right? Because it's like, wow, I'm really important. All these people hate me. They're all mad at me, like I'm in the mix, I'm in the fight. I'm really making a difference.

[00:36:09.310] - Speaker 1
Unbelievable.

[00:36:10.210] - Speaker 2
And so I think a lot of it is just this emotional thing. It's like a heroin kind of thing. And I think there's a hangover from it. I think actually, a bunch of companies have that hangover right now. A bunch of companies have been damaged very badly by this and they have severe internal problems. I mean, look, there are big companies where the CEO no longer runs the company. Like the company is run by the mob, right? I mean, just the employee base can just freak out and threaten to protest or threaten to quit, and the CEO just rolls over every single time. And so at some point, what is that? Is that a company or is that like a social movement wearing the skin suit of a company? So I'd say optimistically, you might say this was a moment in time phenomenon and that mean reversion will kick in. And then you might also say, no, look, we just live in a different world now. We live in a different kind of culture. We have a different kind of media. This is never going back. And I think it's very much related to the question of like, do politicians, quote unquote, become normal again or do they actually become kind of stranger and stranger, more and more unusual?

[00:37:10.600] - Speaker 2
I think probably things just get weirder.

[00:37:13.730] - Speaker 1
I think so, too. I think it'd be hard to go back because if you see now when you look at the politics of the old days, it was a very lawyerly, it felt less connected to the people. It felt like a different elite class. And now it feels more like, whether it's AOC or MTG, it feels like the people.

[00:37:36.770] - Speaker 2
Well, and by the way, just the fact you can name them, right? The fact you can name them, the fact that those two, I already have iconic three letter names, it's like they're right up there now with MLK. How did that happen? Right. The fact that if you poll, if you did like unaided surveys, they would pop up. Those two people might be other than Trump and Biden, those might be the top respective Democrat Republican today for unaided awareness. If you talk to institutionalists in DC, they're very frustrated by this because they view it as like, okay, the people who are purely focused on media presence are getting all the, they're basically getting lined up to be future presidential nominees, whereas the people focused on substance. Nobody knows who they are. And it's kind of like, okay, maybe that's just the world, right? And maybe if you're going to be a politician, that's the world you have to live in and you have to be willing to, you have to have a strategy on that. And maybe if you're in business, this is just the world you live in and you have to, I don't know, pick on people.

[00:38:25.610] - Speaker 2
But look, Disney went through a version of this with Bob Chappick, who I know, and he tried very hard to keep them out of know. First thing he did when he came in was, you know, we're staying out of politics. We want everybody to buy the, and like, the company just was not having it. And Bob Iger has come back and he very much doesn't have that know, he's keeping them in all these, you know, who had the right strategy? I don't know, but it's going to tilt one way or the other. And so I think there's a lot to that. I also think, look, I think that I'm not a big fan. I think there's a lot of simplistic kind of accusations that social media is ruining everything or the Internet's ruining everything. And I think those are generally kind of simplistic and sort of incorrect things. But there is no question that media forms society. Society forms media. Media forms society. McLuhan wrote extensively and work that holds up incredibly well about the role that media takes in shaping culture. And look, we live in a different media landscape now and again. We're the dog that caught the bus.

[00:39:19.160] - Speaker 2
We made it. We invented all this stuff. But you might say a critique I might apply to my own thinking on this is like, what did you think would happen when you connected everybody together into a single global media sphere? Right? McLuhan used the term the global village. And what people forget about the term the global village is he wasn't saying that was good. What he was saying is, basically the entire globe was going to globe is going to revert to the behaviors of a village. And the behaviors of a village are very different than the behaviors of a city. Behaviors of a city are, like, cosmopolitan and open minded and, like, embracing of new ideas and so forth. The values of a village are, like, very narrow minded and moralistic and sharp. And villages, like, ostracize people for slight differences in belief. And everybody's watching everybody all the time, and everybody's super critical. Right. And so we actually invented the global village. Everybody's acting like a villager. Know, McLuhan would say, yeah, no kidding. Like, you know, great job, guys.

[00:40:09.980] - Speaker 1
The great benefit of the villages in the past was that you'd go to another village and they'd have their whole own way of doing it.

[00:40:16.790] - Speaker 2
That's right. And if it's a global village, right, your biodiversity of villages is gone.

[00:40:21.400] - Speaker 1
Yeah. It just gets all turns into the same.

[00:40:23.660] - Speaker 2
The same thing. And so, look, I think this is a big problem. I think this would be my interpretation of the drunk on politics thing, which is just like we became drunk on being sort of domineering members of a global village. They thought they became both company ceos, but also a lot of activists became sort of convinced that they were in a position to kind of steer the totality of human civilization, society by using these technologies. Look, I think there's some truth to that. So we've all gotten basically wrapped up in a collective, single collective psychodrama. But look, I also don't think 8 billion people want to be wrapped up in a single collective psychodrama. And, I mean, if anything, there's just, like, at some point, adrenal fatigue, at some point, it's just tiring to be onto the next howling outrage, right? How many of these can you actually go through? It's actually even funny. Sitting here today is like there are still people trying to push the same buttons they were pushing. In 2020, they'll attack companies or whatever, and in 2020 some accusation will be leveled on something race or whatever related. And in 2020 it would have led to a huge crisis.

[00:41:23.060] - Speaker 2
And today people are pushing the button and just nothing's happening. And it's just because it's just like the 80th time you're going through a race panic.

[00:41:31.050] - Speaker 1
The boy who cried wolf.

[00:41:32.040] - Speaker 2
The boy who cried wolf and it's becoming so clear that so much of that is like astroturfed and is cynical. Manipulation ploys and like using emotional guilt to try to manipulate people to do what you want. And people trying to make money by selling their newsletter or whatever it is where they're talking about how evil everybody, at some point it's just like, all right, I got the message, okay, I guess we're all evil. I don't know. I'm tired of feeling bad all the time. And then, by the way, at some point you get the actual full on backlash, right? Because the other thing the Internet does is it's the opposite of a global village. It also makes outlying ideas much more accessible. And so if you've had it with a prevailing view on something, the Internet is the best medium you've ever had to be able to go basically find the other side. And so you find, I think it's like there's a power law curve like this thing where there's like a small number of global village dominant ideologies that basically suck people in at sort of mass numbers. But then there's also this long tail thing where there's 1000 entrepreneurial efforts to have new kinds of cultures, new kinds of art forms, new kinds of creativity.

[00:42:27.910] - Speaker 2
And those have always existed, but they've always been fragmented and scattered. And it's always been hard to find your little micro kind of tribe of the things that are interested in what you're interested in, especially if you don't live in the same place. And the Internet now makes it possible to find the alternate view of basically anything. And it makes it easy to find the other people who like that alternate view.

[00:42:45.610] - Speaker 1
And so you'll have same with products like Etsy. It's fun to go to Etsy instead of Amazon. It's just a different experience.

[00:42:51.460] - Speaker 2
Right? And by the way, you can pick and choose, right? As a consumer, that's a great example, you can pick and choose where you can buy your stuff on Amazon because it's a garbage bin. I just don't care that much. Versus your water bottle. You want something handcrafted. Right. And so the choice side of it is there and it's really being blown out. I continue to have a lot of faith in people, and I don't think people want to live in a vortex of just uniformity and sort of mutual shaming forever. I think that at some point people want to do different and new things, and I think that the Internet also makes that possible.

[00:43:27.610] - Speaker 1
Do you think the big tech companies are too big to fail? So could something come and replace Google for search?

[00:43:36.120] - Speaker 2
Yeah. Well, let me start with the goal of every company is to become too big to fail. The goal of every company is to become a monopoly. The goal of every company at some point is to get the government to give them monopoly status and to protect them. And so there's this term, regulatory capture. So big companies hire all these lobbyists and at some point what they're trying to do, basically, is they're trying to write laws and then get their own people into key positions at regulatory agencies so that the government basically becomes basically their overseer and their protection.

[00:44:02.470] - Speaker 1
To prevent people from growing, to compete.

[00:44:06.510] - Speaker 2
Yes, to prevent people like us from backing founders like we back who are going to develop the disruptive thing that's going to ultimately hollow them out. And so, and by the way, this is a cycle. Like all of our companies grow up and they want to do that too, right? So this is a cycle, right? In this one, we're both the dog and the right venture capital funded Google. Google is now trying to do what I just described. They have this active effort underway to try to get government regulatory protection. And then we are back in the next generation of companies that are trying to basically screw that up. I mean, look, Google, this is very public right now. Google's going through exactly the process you just described right now with search, which is, does AI make search right? Like, does it make any sense to go search and click on links if you just have a shared GPT that can just give you the answers? And that's a very big product question for Google. And then there's also a very big revenue question in there, which is 99% of Google's revenue comes from ads.

[00:44:53.400] - Speaker 2
The ads are these keyword ads on search results. Does that happen in, if the user is not clicking on links, are they clicking on ads? And so will there be ads in AI? Or even if there are ads in AI, will those ads work the same?

[00:45:06.570] - Speaker 1
And what's your prediction? How do you see that playing out?

[00:45:10.060] - Speaker 2
Yeah, look, and I would say, look, Google was in this interesting position where, number one, they invented a lot of these AI technologies, right? And so the key breakthrough for Chat GPT, actually happened at Google in 2017. In classic big company form. They sat on it, they didn't use it. If you talk to people in Google, they will tell you that Google could have had Chat GPT. Four, the way you have it today, they could have had it, had they been focused on it, but they decided not to do it. So this is like a classic big company thing. Now they've woken up, now they feel threatened, they understand everything I just said. And so they've got this internal effort called Gemini, and they're going to try to lead Prague. Chad GPT and Sergey Brin, one of the founders, has come back to work on that.

[00:45:45.890] - Speaker 1
But how will it work for the ad model?

[00:45:48.040] - Speaker 2
That is an open question. That is a very open question. I would give two assumptions. My assumption is, number one, yes, a transition from search and ten blue links with ads. There will be a transition from that to just ask a question, get an answer. And I think that transition is underway right now. I think Google's going to. They're already starting to launch their own version of that. So when you do Google searches now, and a lot of those searches at the beginning, they'll actually just try to give you the answer. They're trying to lean into that. So there's that look on the ad side. The argument for ads and AI is actually quite similar for the argument for ads and search, which is basically like, if you're searching, like, I don't know if you're searching, should I go on vacation? Right? And it's, you know, how about this beach in Thailand? It's like, okay, well, the very natural next thing to do would be I'm going to click and buy a ticket and I'm going to click and buy a hotel reservation, right? And so presumably people are going to be talking to the AI about things that they ultimately want to buy, and then there will be an opportunity in there to actually be helpful, to actually have an ad that actually makes it possible to do the thing that you're talking about.

[00:46:40.010] - Speaker 1
Seems like if you're going to something for information, if they have an interest in selling you a particular thing, that undermines their ability to give you the best information.

[00:46:53.530] - Speaker 2
So the history here is that the search ads was actually not invented by Google. It was actually invented by a different company in the 90s, this guy Bill Gross, actually down here in LA, I think it was called Goto.com at the time. And they were the first company that rolled out a search engine where there were ads, there were sort of ads in between the links and it was actually viewed out of the gate as like unethical for that reason. And it was like, oh, this is bad, because it biases the results. And by the way, look, there's some truth to what you're saying. Now, there's a commercial incentive.

[00:47:22.850] - Speaker 1
I can't imagine a version where it's not 100% true.

[00:47:26.300] - Speaker 2
Well, but here's why it's not 100% true. Because there's utility value to it.

[00:47:29.830] - Speaker 1
Right, but you don't know because of bias. We don't know that.

[00:47:35.780] - Speaker 2
Yeah, but at some point you want to buy something, right?

[00:47:38.170] - Speaker 1
Yeah, but how do you know what to buy? If the thing that you're trusting to give you the information is trying to sell you one of many, that's a problem.

[00:47:46.860] - Speaker 2
Well, so here's the other thing that happens. And you might view this as making the situation better or worse. If they don't sell these ads on fixed price basis. They're auctions. Ads are priced on auctions. And so the ad that you actually see is the guy who's willing to pay the most to present the ad.

[00:47:58.770] - Speaker 1
So it's not based on the best service.

[00:48:00.720] - Speaker 2
It's not based on the best service. But it's also not just a lowest common denominator thing either. It's the person who can justify paying the most for the ad. And it turns out there are a lot of product categories where the guy who can pay the most for the ad has the best product.

[00:48:10.850] - Speaker 1
That's a real stretch. That feels like a real stretch.

[00:48:13.510] - Speaker 2
Mercedes spends a lot more money on that form of advertising and marketing that does.

[00:48:17.670] - Speaker 1
To someone who says that's the best.

[00:48:19.430] - Speaker 2
Product than Toyota does. But generally speaking, in the world, the argument goes, the better the product, the more expensive the product, the more the company is going to spend on advertising it.

[00:48:27.720] - Speaker 1
Do you believe that?

[00:48:29.210] - Speaker 2
I think there is a point to it.

[00:48:30.970] - Speaker 1
Generally speaking, I'm not saying, can you argue it? Do you believe that?

[00:48:33.770] - Speaker 2
Well, look, a lot of times when I'm looking, okay, I'll give you something. A lot of times when I'm looking for something and I'm just like, I just want to buy something and I don't want to spend the next week trying to research it and navigate it, trying to correct for all the biases. And I just need the thing. It's like a pretty good proxy. It's like, okay, if they're willing to spend $40 to get this thing in front of me, click right.

[00:48:51.040] - Speaker 1
Wonder about that.

[00:48:51.960] - Speaker 2
Because the guy. Because the key is self interest. Like, if they weren't making money with the $40, then they wouldn't be spending the $40 like they spent the $40 even before they knew whether I was going to buy it. And so it's costing the advertiser real money to run the ad. And so there's some proxy there for. They have a healthy.

[00:49:06.780] - Speaker 1
It just means they may be the best funded.

[00:49:09.290] - Speaker 2
Yes. So there are moments, there are times, there are times when the categories get overfunded. But most businesses, this is where self interest kicks in and helps you, which is most businesses need to make money over time to do that. They need to calibrate how much money they spend on marketing versus everything else. And over time, if they can afford to spend money on marketing, they probably have a pretty good product because a lot of people are probably buying it. Right. And if they don't, they don't. The look on your face is the look that everybody had in the 90s when this idea first rolled out. And it was exactly this argument. It turned out it worked well.

[00:49:39.040] - Speaker 1
It worked in that people have gone along with it.

[00:49:42.680] - Speaker 2
Yeah, they have.

[00:49:43.620] - Speaker 1
People have given up the search for the good thing in exchange for the convenience of, somebody wants to sell me this and they're telling me what to buy.

[00:49:53.520] - Speaker 2
Well, here would be a question. Are people more or less likely to buy the better version of the product out of all the choices today than they were before?

[00:50:00.550] - Speaker 1
The Internet depends on the person.

[00:50:03.860] - Speaker 2
Yeah. Okay. But a lot of people part of this, there's also just a fading of memory thing that I think that happens, which is pre the Internet, it was actually really hard to get any information on products. That's true. Right. And so God help you try to find, well, this is a big issue in the car industry for a long time. It's like some cars were just much more fundamentally prone to breakdown than other cars. But it was actually really hard to figure that out. And it was hard to aggregate. It was hard to either have an authoritative voice that would tell you, or it was hard to actually have an environment where people could tell each other. Right.

[00:50:30.390] - Speaker 1
Consumer reports. Consumer used to do it.

[00:50:33.490] - Speaker 2
They built a big business. They built a big business because of that. Right. And there was a certain, as you remember this, there was a certain kind of consumer who was glued to consumer reports and used it as the bible for everything they bought. But there were a lot of people who didn't because there's a lot of people who just have other things going on in their lives. And so I think, on balance, the Internet has made it so that better products have done better relative to worse products. I mean, there's basic examples, which is, remember when you used to mail order, you used to mail order things, wait four to six weeks for delivery.

[00:50:57.920] - Speaker 1
Yeah. You had no idea what you were going to get.

[00:50:59.530] - Speaker 2
Right. Yeah, exactly. And there was some drawing in some catalog somewhere and whether it was even the product. Right. And so today, everything's overnight. There's reviews and ratings and again, is it perfect? Are there fake reviews?

[00:51:11.380] - Speaker 1
It's definitely better. And you can order several different options and you can see the one that works for you and everyone understands because it's mail order, things get sent back. I definitely prefer it. Now, that's a different question, though, than the corruption built into the system.

[00:51:29.110] - Speaker 2
There's some disconnect. Look, having said that, Google, again, I'll defend Google's honor. Just one more step, which is Google doesn't care. Google is running an auction. They're optimizing on price of what the person's willing to pay to put the ad in front of you. So to my knowledge, they're not putting their thumb on the scale. Like, they're not basically saying we're going.

[00:51:45.940] - Speaker 1
To rig like Amazon is.

[00:51:47.400] - Speaker 2
Well, so Amazon's in an interesting spot. Are Amazon ads surfacing the high quality products?

[00:51:52.540] - Speaker 1
No, not even the ads. Amazon, if you're looking for whatever, often the first recommended choice from Amazon is the one that Amazon makes.

[00:52:03.200] - Speaker 2
That's also true. Yes, exactly. And there's a government investigation now where the FTC is trying to basically force them to stop doing that.

[00:52:08.910] - Speaker 1
Is that true?

[00:52:09.390] - Speaker 2
Yeah, for that reason, I don't know whether what will happen with that case, but they're trying. So take all of your points, I think. Well made. Look, this is all going to get rethought in the AI world, right? So look, should the AI have a view? Should the AI have opinions of product quality the way it has opinions on everything else? Well, so, Elon, this is also happening in social media, right? So Elon has this thing now, community notes, right? For X, where it has this thing, it.

[00:52:33.960] - Speaker 1
What is it and how does it work?

[00:52:35.210] - Speaker 2
Okay, so it's this very clever thing. So all these social media companies, these social media companies all used to be free speech freed. Free speech wing of the free speech party. And then it just turned out a lot of people said a lot of things that made people mad. And so these companies all created what they called trust and safety groups. And of course, that is like a super orwellian terms. It means you can't trust them at all and they're totally unsafe. And so what you ended up with in the trust and safety groups was just basically, you had some well meaning people, and then you had a lot of people who were in there to basically put their thumb on the scale. And this really kicked in around politics. Know, they would have just obviously know standards, know candidates from different political parties, that everybody could kind of see it in plain sight. And so that model never worked very well. And so the people at Twitter, and I think this actually started before Elon got there, but he embraced it when he got there. They came up with this new idea called community notes.

[00:53:21.500] - Speaker 2
The idea of community notes is that anybody, there are people who have the button to be able to submit a community note, which then there's a way that you kind of apply and you become one of those people. It's like being a Wikipedia editor or something like that. Right? And so there are certain people who can propose community notes, but a community note does not get approved and used unless people who have a history of disagreeing agree on it. So, for example, we see a statement, somebody says something, and it's just like, it's wrong. You and I are two community note editors. We have a history of political disagreements, we have a history of conflict where we really don't see eye to eye on things. But then this time we see eye to eye.

[00:53:57.000] - Speaker 1
I see.

[00:53:57.540] - Speaker 2
Right. And then that's the one, that's the note that gets posted. Right. And so I would say it's been working shockingly well. And by the way, it's not perfect because it goes wrong. And there people try to trick the system. But it's by far the best system that I've seen that actually works. So he's done this very clever thing, interesting thing, where you can now do community notes on ads. Right?

[00:54:15.500] - Speaker 1
On ads.

[00:54:16.080] - Speaker 2
On ads.

[00:54:16.770] - Speaker 1
Interesting.

[00:54:17.850] - Speaker 2
If somebody runs an ad that makes false claims, right, or exaggerates something, it can get community noted. And so the platform itself is like, oh, actually the claim in that ad is actually not correct. Here is the actual truth, and here are the links for the truth. You can imagine the reaction of the advertisers. I mean, right? They're just like absolutely furious every time this happens. But he's running this experiment basically saying, is the faith and trust of the user base being improved by the fact that the community notes can actually be legitimately fact or the ads can be fact checked. Is the value of that greater than the lost value of the advertisers who get alienated? And by the way, he would say the advertisers who get alienated by that are probably the worst advertisers anyway. Sure. Because there's some issue.

[00:54:54.920] - Speaker 1
It's surfacing if you're making a product. And if people have a problem with it, if you're the maker of it, you want to know that.

[00:55:02.700] - Speaker 2
If you're good, right? If you're honest, absolutely. That's right.

[00:55:05.610] - Speaker 1
Absolutely. If you want to improve your product, to always be the best it could be, of course you would want to know that.

[00:55:11.040] - Speaker 2
And if you don't, maybe you should not be advertising.

[00:55:13.150] - Speaker 1
Exactly right.

[00:55:13.790] - Speaker 2
Maybe you should not be allowed to advertise. And so I think that's a very clever experiment. And I think there's a lot more of this kind of thing. There's a lot more experiments like this. People can run. I think in the next 20 or 30 years, we'll figure out actually a lot. This is all around trying to make the global village work better. Like, this is how to get basically 8 billion people to kind of share a mind space and not want to kill each other. And this is the kind of technique that I think you can start to figure out.

[00:55:38.480] - Speaker 1
Can a company grow too fast?

[00:55:40.270] - Speaker 2
Oh, yeah, for sure.

[00:55:41.110] - Speaker 1
Tell me about it.

[00:55:41.780] - Speaker 2
Yeah, very common. Very common. Yeah. Well, so especially when either the revenue just starts to pour in or when they raise too much money, the basic mechanic is very straightforward, which is just, you have a problem. If the answer is you can always hire somebody to fix the problem, then that's what you'll always do, because it's the easiest thing to do. Right. I'll just go hire another engineer. They'll just go do that. The problem is, it's like any human organization. Like organizations behave very differently when they're large versus when they're small. And there are big issues involved in running large organizations that are very complicated, and it's very easy to run them badly. And it's very easy that I use the metaphor of Elvis leaving the building. Like, it's very easy for Elvis to leave the building. Company grows too fast, the good people quit, the bad people stay. We have another thing we call the law of crappy people, which is in any organization, these organizations have levels. So there's like, levels of promotion levels, level one through eight or whatever. And there's always an internal process to try to figure out when people should get promoted.

[00:56:37.790] - Speaker 2
And so the law of crappy people says that the quality of any level in the company will degrade to the worst person at that level. Right. And it's a very natural human thing, which is just like, well, I want to get promoted to level three, and I know I'm better than that other guy who just got promoted. Right. And so whoever is the worst person at that level now sets the bar. And so basically, as companies grow, basically, performance tends to collapse kind of level by level. Meetings, communication, overhead overwhelms everything. People are just sitting in meetings all day. Or another thing that happens is you hire too many people from another culture. So you think you have your unique culture, and then you hire 300 people from Google, and you discover all of a sudden that you're Google all over again, but without their business, just with all their problems. Yeah. And so I would say this is part of the more companies die of indigestion than starvation. Right. Because starvation is no fun, but starvation is highly motivating. Right. If you don't have any money and you only have a few people, you have to be smart.

[00:57:35.140] - Speaker 2
If you are flush with cash, you can try to spend your way out of all your problems. You could say there's a metaphor here for individual lives. Right. Which is like, a lot of people get in a lot of trouble.

[00:57:45.250] - Speaker 1
Yeah. I think that's why I was asking about if people mainly came to you for money, because it seems like money is not at the highest level of what it takes to make great things. It's a piece of the puzzle, but it's not the main piece of the puzzle. I don't think. It hasn't been in my experience.

[00:58:01.550] - Speaker 2
I'll say it has been. That's right. Yeah. And I think that we find ourselves in. And people don't believe this. We find ourselves in practice often trying to get our companies to not raise as much money as they can kind of down the road. Yeah. Look, we just tell them, like, look, it's just bloat. Like, just simply bloat. Like, look, you know how to run this company of 50 people. Everybody feels great. You just need to close your eyes and imagine that that's not how your day is going. Your day is going. Organizing meetings on calendars and cross.

[00:58:24.890] - Speaker 1
And if you can grow the company with the 50, why would you hire more?

[00:58:28.890] - Speaker 2
Yeah. Now, usually you do. So there are some companies, there are a small number of companies that become big and important with very small numbers of people. And there are these kind of very magical successes.

[00:58:36.960] - Speaker 1
Give me an example.

[00:58:37.770] - Speaker 2
So the great one was Minecraft. So minecraft at the time that it sold was, I think three people total.

[00:58:42.880] - Speaker 1
Wow.

[00:58:43.980] - Speaker 2
Which was.

[00:58:44.540] - Speaker 1
And what did it sell for?

[00:58:45.490] - Speaker 2
Remarkable. I don't know, a billion and a half, 2 billion or something. But it was this giant global phenomenon and now it's owned by Microsoft and now there's a lot more than three people working on it. But it's an amazing thing. I mean, look, bitcoin was like one guy that's worth like $800 billion today or something. So there was that WhatsApp, when they sold it to Facebook, it was 50 people. Instagram, when they sold it to Facebook was I think eleven people. So you have these kind of very kind of special things. Midjourney is one guy, plus basically a bunch of contractors. Huge kind of force now in art, AI. So you have these kind of very special things. It's just, they do. At some point this is the pressure on the other side. At some point there are things that are just kind of obvious that these things should do that they just don't do.

[00:59:32.070] - Speaker 1
Understood.

[00:59:32.660] - Speaker 2
Like Minecraft was like a know, kind of viral phenomenon. But it really should be what Microsoft's turning into today. It should be entire world and there should be, it should be like you should be able to use it for education and it should run on all these different platforms and it should have all these different kinds, all this new content and it should be this thing that people can be in years. It's much like deeper and richer and more built out than it was. Same thing, WhatsApp. This is what's happening at meta right now is WhatsApp. WhatsApp is very widely used. It's one of the main ways that small businesses communicate with their customers. But there's been historically no capability inside WhatsApp for a small business to be able to maintain a customer database or whatever inside WhatsApp, which is like a very obvious thing like for a restaurant or something. And so there are things like that that make sense to add that are actually valuable to the users that just require more people. So yeah, there's pressure on the other side to grow. It's just there's some theoretically optimal rate of growth of heads and it's very easy to, it's one of those things where nobody ever quite gets it right.

[01:00:29.340] - Speaker 2
Well, and then look, the other thing that happens is the economic cycle. Like these companies all tend to overhire during an economic boom. And then at some point there's a crash and there's a rationalization and you kind of wish, you always wish that you didn't have to go through that because it's bad to do layoffs, but it's very hard to just keep that. It's very hard to, over time, have a sustainable model where you don't make mistakes.

[01:00:47.040] - Speaker 1
How did you meet your partner? Ben?

[01:00:49.260] - Speaker 2
Yeah, so I met Ben. We were actually trying to staff up at my first company, Netscape, in 1994. Yeah, we were desperately, we had the tiger by the tail. The Internet was going to take off and we knew it. And so we had to kind of get in position. And so we were trying to hire in good people. And he was one of the first people who came in from an existing successful software company to join us. And he's a young guy, came in as was called a product manager. So somebody who kind of orchestrates things. And then very quickly it just became clear that he was one of the sort of sharpest young people we had. And so we promoted him very rapidly over the course of the next few years. And I ended up working very closely with him. And I always thought, had we stayed, we sold our company in 1998, four years in, but just an eternity that turned out was only four years. If we had stayed independent, I think he would have ended up being the CEO. He was on track to do that. So I spent a lot of time with him and we got to know each other really well.

[01:01:38.260] - Speaker 2
And then, so it sort of became obvious after we sold our company, I wanted to start a company. And so it became obvious he would be the right person to do it.

[01:01:44.950] - Speaker 1
Is it as much a friendship as it is a partnership?

[01:01:48.120] - Speaker 2
There's an old thing around founding teams, just generally, which is what? A friendship from a business relationship works better than a business relationship from a friendship. Like when two people who are personal friends go into business together, it often destroys the friendship, whereas people who have a business relationship first and really learn to trust each other in business can become very good friends. And so for us, it's been that ladder. It was business first, and then it's become a very deep friendship. We talk all the time and we get along great and we're always teasing each other and it's all good. Having said that, it's now almost 30 years. Wow. And so there also is an old married couple kind of aspect to it, right? And some of that is we can finish each other's senses and some of that is we get on each other's nerves. So we still argue all the time.

[01:02:34.010] - Speaker 1
It's interesting. What would be something you would argue about?

[01:02:36.120] - Speaker 2
Oh, just constant arguments. I mean, about basically everything. Well, it's obviously a big benefit of a partnership is you have somebody you can actually talk to, who you trust, who can actually tell you things that when you're getting things wrong. So we argue about. But the biggest argument is always around people. Is this person good or not? Should we promote this person? Should we fire this person? Some of that's around our firm. A lot of that's around the companies we work with. He works with a lot of our ceos. He's our, among other things, he's like our management guru. So he's the guy who basically works with all the sort of most high potential ceos to help them kind of develop. And so he develops kind of.

[01:03:10.190] - Speaker 1
He wrote the book on it.

[01:03:11.060] - Speaker 2
He wrote the book on it, exactly. Hard thing about hard things, but it's consequence. He's legitimately very opinionated about people kind of coming out of that. I would say he's more focused on culture. He's extremely focused on the culture of the company that a CEO is developing. And he applies that in our firm, but he also applies that to the ceos that he works with. And so he really wants to understand, when he's evaluating a founder, he really wants to understand what culture that person is building inside their company. I'm a little bit more open to variations. I'm more open to what he might call recklessness or chaos or original thinking that maybe doesn't work. It might blow up in your face. And so I'm always a little bit more on the side of maybe we.

[01:03:54.080] - Speaker 1
Should like, would you say you're more of a risk taker than he is?

[01:03:57.030] - Speaker 2
I would say it's different kinds of risks. I think we're pretty similar in aggregate. It's different kinds of risks. I'd be curious whether actually he would agree with this is I think he thinks, and I think he's right, but I think he thinks there are kind of timeless ways to build great cultures. Leadership is not a new idea. Right. It's something that has existed for a long time. Cultures. His second book is actually on culture, right. And he goes through, he talks about, like, Genghis Khan and the Mongols, and he talks about the code of the Bushido and the samurai and kind of these cultures. And he's very into that kind of thing. And so he draws a lot of historical examples for cultures, and he's like, look, these are these continuous threads of like, what does it mean to have people trust you to be able to bond together into a team? Right. All these things. The other side of it is, look, people who come up with new ideas often have new ideas on everything. And so a lot of the people who have new ideas on technology AlsO have new ideas on management and culture and how to be a CEO and how to structure a coMpany.

[01:04:48.370] - Speaker 2
And do We REALlY need all THEse meetings, and can we just run everything on video conference? And DO we even need to have Those, or can we just do everything on slack? And so a lot of these founders will have these very creative, original ideas on how to actually run their companies. And I would SAy most of the time, his SPeeCH to them would be, stop. Focus your creativity in the area that you actually understand, which is building products or designing things, and then just get good at running the company the way that companies have been run for hundreds of years. Like, don't try to innovate on everything. And I would SAy he's usually right on that. USuALLy ThoSE experiments end. A know that said, every once in a while they don't. And every once in a while, there's a totally new approach. And just a case study of this right now is elon. We work with Elon. I've known Elon for a long time, but Tesla and SpaceX predated us as a venture firm. But we're involved in his Twitter kind of acquisition, and Elon has a completely different way of running. And you could read ABOut this.

[01:05:42.720] - Speaker 2
The press has covered this at length. Right. It is a much more blunt, chaotic, hair trigger, direct engagement way. He is very quick to hire people. He's extremely aggressive. He micromanages the nth degree. He's involved in everything. And it's a playbook that for most CEOs would lead to disaster.

[01:06:00.690] - Speaker 1
Wasn't that the case with steve jobs as well?

[01:06:02.680] - Speaker 2
Yeah. So steve jobs. This is a good POInT. So Steve was a genius with a dark side, and the genius was real. And the DaRK side was real. EverybodY's seen the results, and the results obviously make the whole thing worth it. But Steve could be really rough on people. And there are many true stories about Steve being really rough on people. And this would be a great example. Ben's view would be, yeah, you just don't do that. You figure out how to be great without know being rough on people. Like, you know, I would say, like, in general, that's the best advice. Right. In general, if you're coaching a young kid on how to run a company that you want them to try to calibrate that, because generally, if you're really.

[01:06:35.440] - Speaker 1
Because you don't really get anything for that behavior.

[01:06:38.300] - Speaker 2
Well, Steve did.

[01:06:40.360] - Speaker 1
Well, we don't know that because he didn't have Ben coach again.

[01:06:43.540] - Speaker 2
Okay, so this would be the argument. Okay, so this would be maybe the argument that Ben and I would have about it, which is Ben would say what you just said. Ben would say, no, that was purely destructive. If Steve had not done that, he would have been even better.

[01:06:54.510] - Speaker 1
Well, we don't know. There's no way to know. But I do think that's a real question.

[01:06:59.240] - Speaker 2
It's a real question. I can make the other side of the argument.

[01:07:01.540] - Speaker 1
Tell me.

[01:07:02.170] - Speaker 2
The other side of the argument is a players want to be in a company of all a players. People want to be around other great people. Most companies are way too tolerant and indulgent of mediocrity. Most companies are good at getting rid of just like call shitbirds. They're good at getting rid of people who just are clearly no good. What they have trouble with is mediocrity good, but not great. And Steve just could not tolerate mediocrity. And so when he identified that there was a term called flipping the bozo bit, and when he flipped the bozo bit, he fired you that day. Because what he had learned over time, in his view, was that you never unflip the bozo bit. Right. You just need to call it right up front.

[01:07:36.100] - Speaker 1
And Ben would disagree with that idea.

[01:07:37.910] - Speaker 2
Yeah. He would say, look, it's just two hair trigger. Like, you're in a meeting with somebody and they say one thing that's wrong and you fire them on the. Like, how do you. You're not, like, you just happen to be in that meeting. And look, maybe his wife yelled at him this morning, or maybe his kid just died. You don't know what.

[01:07:52.430] - Speaker 1
And also, maybe he's actually right because it does happen sometimes.

[01:07:56.280] - Speaker 2
Exactly. Maybe he's right. Yeah, exactly. I'll tell you, the conversation we had on this that really made a big impact on both of us was with Andy Grove, who was. Passed away. But when he was running intel, he was considered kind of the best CEO in kind of the history of the tech industry. When we were young, we used to meet with him and he would help us on things. One of the questions we had for him was like, wow, it always feels like we're firing people too late, right? It's like, every time we fire somebody, it's like, wow, we wish we had done it, like, nine months sooner, right?

[01:08:23.990] - Speaker 1
Because they had done damage in that nine months or because you missed an opportunity for something better? Both.

[01:08:30.040] - Speaker 2
Well, it's this flipping the bows a bit thing. It's like, okay, we identified that they had an issue, a problem. Every once in a while, people can turn it around, but most of the time, in a workplace environment, if you've got competent management, when they identify that somebody has an issue, generally people don't turn it around. Statistically, they just generally don't. And so you have this thing where if you're running kind of the standard management playbook, you put people on what's called performance plans, and you try to more aggressively kind of coach them for improvement. And then they normally don't make it through. And then at some .3 months or six or nine months later, you kind of make that call. Actually, the reason you put people on performance plans is because most companies are too indulgent of mediocrity. And so most companies don't aggressively performance manage along the way, they don't document things along the way. And you need to put people on the performance plan that have the legal justification for firing them because you need that paperwork that you actually did evaluate them. But you're just like, shit, I'm wasting time. This person is doing a mediocre job.

[01:09:20.540] - Speaker 2
They're infecting the organization with mediocrity. I wish I could move faster. So we asked Andy, basically, is it normal to always feel that you're firing people three months or whatever, nine months too late? And he's like, yeah. He's like, that's what it always feels like. And he said, the reason is because if you did it more aggressively than that, the organization would view you as a sociopath. Right? And it's like, well, Steve didn't care about being viewed as he was like, yes, I'm not optimizing for what people think of me. I'm not optimizing whether people think that I'm nice. I'm optimizing that the people around me are going to be at the top of their game. And if they're not, they're going to go, right. And Elon's the exact same way. And then the results. And again, this is the argument Ben and I have is like, okay, Apple, Tesla, Rockets, Atlanta, their butts. Oh, my God. Is the Steve Elon playbook, like, the more aggressive playbook, actually the one everybody should be having? And Ben's comment to that is, no, most people will destroy their organizations if they try to do that. That doesn't actually work.

[01:10:17.850] - Speaker 2
I go through all of that just to say, yeah, that's the kind of debate that we'll have. And look, it's not resolved. Right.

[01:10:23.360] - Speaker 1
Quite honestly, it's unknowable.

[01:10:24.870] - Speaker 2
It's unknowable. I don't think it ever will be resolved.

[01:10:26.850] - Speaker 1
Tell me why a company would choose to stay private and why it would choose to go public.

[01:10:32.060] - Speaker 2
So most of the great business institutions that are around for many decades, most of them are public companies. And the reason is because they end up with a lot of employees, they end up with a lot of customers, they end up with a lot of constituents, they end up with governments getting very interested.

[01:10:46.400] - Speaker 1
Are there any that are private?

[01:10:47.680] - Speaker 2
Yeah, there are big ones. There's a bunch. One prominent one would be coke industries. Charles Coke. It's a giant industrial company. And they do like, they're huge. They're a giant, they're big. I mean, I don't know. The numbers are just titanically large. They'd be a Fortune 50 company tomorrow if they went public. But he's kept it private the whole time. Bloomberg is another. Bloomberg the company. Bloomberg is another example of a big.

[01:11:08.680] - Speaker 1
That's a private.

[01:11:09.420] - Speaker 2
Private company has always been private. Mike Bloomberg just owns it outright. So, yeah, they exist, but most of them end up public. And I think the reason they end up public is just because if you're an institution, at some point you kind of have to act like an institution. You have to be trusted institution. So you have to be transparent. People have to know what you're doing. Public companies carry with them these responsibilities to report to the public. You have to explain yourself in a way that's very open. And you're under these very stringent legal requirements to do so accurately. So people tend to trust the things that public companies say more than private companies.

[01:11:37.850] - Speaker 1
How accurate are those results?

[01:11:39.840] - Speaker 2
So in the United States, I would say quite accurate. Either they are wholly accurate, or if they're not, they're off a little bit. Outside the US, it is still the wild west. So we went through a series of scandals in the US business world. We went through a series of scandals in the 2000s around Enron and companies, Worldcom and companies of that era. And the stringency of the accuracy of the reporting and the level that you get reviewed by the government and the penalties to lying are quite high now. And look, most responsible people want to run something that is legitimate and genuine, right? There used to be an old thing. Used to be an old thing I used to hear when I was a kid, which is like, remember there was this gangster named Myelansky that famously ran the big part of the mafia in the US. And people used to say, well, Myelansky was so successful as a gangster, just imagine how successful he would have been if he was running General Motors. Right? I think that's actually untrue. Right. I actually think Myelansky is actually very ill suited for running a big public company because you get caught lying and you break somebody's legs and it's a big problem.

[01:12:39.930] - Speaker 2
Right. That's not what a trusted institution does. Right. And so the best and the brightest actually, I think, want to be legit. They want to do something that's actually genuine, and that's true for companies as well. Look, having said that, outside the scandals, I mean, even Europe, the scandals in Europe are like minding. And then once you get outside the developed world, things get really hairy. So most of the world is not well developed on this stuff yet. But anyway, so there's the transparency kind of truth telling component to it. There's also the, at some point you want to have a lot of shareholders, like, at some point you want kind of the world at large to be able to invest in your company. You want ordinary people to be able to have a stake in your success. You want kind of everybody to have your stock in the retirement plan, because then it sort of gives everybody a reason to kind of root for the company. Me, at some point you've got all these employees that you're paying in stock. At some point you want them to be able to sell their stock and be able to buy houses and send their kids to college.

[01:13:33.350] - Speaker 2
You also get what's called a currency. So your stock becomes a currency and so you can use your stock to buy other companies. It's easier to raise debt when you're public. And by the way, a lot of employees just want to work for, they want to work for an institution. They don't want to work for some fly by night startup. They want to work for something that's trusted where they can. One of the things I do with candidates a lot of the time is especially immigrants kids. Some kid who's sort of a first generation immigrant is, I'll literally get on the phone with their parents. And this has happened repeatedly where I sort of explain to the parents, like, no, actually, it's okay. It's okay if your kid doesn't go to work for IBM or Microsoft or Google. It's okay if they go to a startup because actually in the US, that's not actually because the parents are worried about career death if it doesn't work out. Right. And so there are a lot of people who just want to work for a stable company. So anyway, so those are all the reasons to go public.

[01:14:22.330] - Speaker 2
The reasons not to is just like, look, you're exposed to all the scrutiny, right?

[01:14:27.480] - Speaker 1
Is it only scrutiny or anything beyond scrutiny?

[01:14:30.020] - Speaker 2
Well, so it's the consequences of scrutiny. So you have a stock price. The stock price trades every day.

[01:14:34.940] - Speaker 1
But do you start making decisions based on the stock price?

[01:14:37.840] - Speaker 2
Big time.

[01:14:38.560] - Speaker 1
But that's not your core business.

[01:14:40.410] - Speaker 2
Correct.

[01:14:40.830] - Speaker 1
Changes your whole business model exactly 100%. That seems bad.

[01:14:44.460] - Speaker 2
Yes. Well, it depends. Yes. So it destroys a lot of. This ruins a lot of companies. So the easiest failure case is that you've been running your company, just running your business the way you run a business, and then all of a sudden, you've got this daily scorecard, and you're optimizing the daily scorecard. Or even if you can get through the day, you're optimizing your quarterly results. You're reporting every 90 days, and you're optimizing for that. When this goes poorly, basically what happens is time horizon contracts, right? And so instead of planning things one 3510 years out, you're planning 90 days out. And nobody can do anything great in 90 days at the scale of these companies. And so you just, basically, this is when Elvis leaves the building. Right. And by the way, often this coincides with, this is when the founders step down and then they hire a professional CEO. Professional CEO is then sort of optimizing for their own compensation. They're optimizing on these short time frames. And so that's a big downside. There are ways to deal with that, but that is a big downside for sure.

[01:15:35.250] - Speaker 1
In your position, when you're investing in companies for ten or 20 year trajectories, if they go public, how does that change your position? Because now they're playing a different game.

[01:15:47.890] - Speaker 2
Yeah, that's right.

[01:15:48.500] - Speaker 1
They're no longer playing the 20 year game.

[01:15:50.530] - Speaker 2
Well, they might be. There are public companies that do. Right, so Amazon played the long game the whole time. Still does. Apple played the long game. They were public the whole time. Steve Jobs did the turnaround of Apple. They were a public company. Look, Tesla's been public for a decade. SpaceX is private. But Tesla's public. And Elon runs Tesla the exact same way he runs Netflix. You know, invests for the long know. There's a lot of these companies that have, I think, done, I can tell you, Mark Zuckerberg at Meta, this hasn't changed how he views know, look, it can be done. It's a higher competency, a little bit more of a high wire act, like you're getting graded by the world on what you're doing. And this is the speech we give the ceos because they're like, oh, well, I'll just do what Steve Jobs did. I'll just do whatever I want. It doesn't matter. And I'll be like, yeah, but you just need to imagine what happens when your stock drops, like, 97% and you're on the front page of every business newspaper in the website in the world talking about what a turkey you are.

[01:16:38.420] - Speaker 2
Right?

[01:16:38.660] - Speaker 1
Have you experienced that?

[01:16:39.620] - Speaker 2
Oh, yeah, of course. Yeah. Multiple times.

[01:16:41.010] - Speaker 1
You have to give me a specific example. What's it like?

[01:16:43.060] - Speaker 2
Oh, yeah, it's horrible. It's awful. It's happened multiple times. Most of these companies, there's this great form of a chart, financial chart called the drawdown chart. And the drawdown chart is basically, its baseline is zero, and then the chart is the percentage drop that the stock has experienced in different points of time. And so it's zero to like a negative 100%. Right? So it's like this, and then it's like what it looks like? It looks like somebody having a heart attack. It's a cardiac arrest. And so I just give the drawdown chart for Amazon is really interesting because, of course, Amazon's just giant success. But there have been, like, I think, five different times in the last 20 years where the stock has dropped like, 97% or something like that. I mean, just like these massive crises of confidence where basically everybody's just like.

[01:17:19.840] - Speaker 1
Yeah, this is, well, it had no profits for how many years?

[01:17:22.470] - Speaker 2
For a very long time.

[01:17:23.330] - Speaker 1
Very, very long time.

[01:17:24.320] - Speaker 2
For a very long time. Exactly. And so you were running the. So what Jeff had was, and he talked about it publicly. He's like, look, we're investing for the long run. We're reinvesting every penny of internal profit back into the business. We're building what they call intrinsic value in the business, and we're just not going to hand out dividends to shareholders. And the investors who went along for that ride did great. But it's easy to say that it's harder to do it when your stock drops 97%. And the headlines, there was a famous cover of Barron's magazine in 2005, and Amazon at that point was already, like ten years old or coming up on it. And it was literally, the headline was literally dot bomb.

[01:17:56.210] - Speaker 1
Wow.

[01:17:56.650] - Speaker 2
Right? Like, Amazon is going out of business.

[01:17:58.630] - Speaker 1
Wow.

[01:17:59.050] - Speaker 2
Right. It's going to be worth zero.

[01:18:01.060] - Speaker 1
Wow.

[01:18:01.430] - Speaker 2
I mean, I went to investor conferences in the early 2000s where people were just openly laughing at Jeff, just, like, laughing at him in the meeting. Like, you're just, like, completely full of it. And look, everybody, part of being a CEO is people are doubting you, whatever, when the entire world is doubting you, because what happens is anybody who's had a career, they've had one of those moments. It has that, which is like, all of a sudden, you're talking to your friends, and your friends, like, are you okay? Right? Like, how are things going? And then you go home, your family's like, are you all right? And you're like, yes, I'm fine. I'm the same person I was.

[01:18:32.520] - Speaker 1
Did you know Jeff at that time?

[01:18:34.220] - Speaker 2
Yeah.

[01:18:35.480] - Speaker 1
Was he fine? Yeah, he was fine. No impact?

[01:18:38.510] - Speaker 2
No. Let me say this. This is the 04:00 a.m.. Thing. I don't know. Since I was not sleeping with today, we have a much closer relationship back then. Back then, I was not sleeping with him. What is he experiencing at four in the morning? That I don't know. Right. And there's only really two people who are in a position to know that. Him and his wife at the time. So that, I don't know. But to the outside world and to all of his friends, he was fine the entire time. And he was fine the entire time, because he's just like, look, we have a plan. We're executing the plan. We're not going to get shaken off of this. Now, look, you could also say a fair response to what I just said is survivorship bias. Right? Like, here I sit talking about the ones that worked. What about all the ones that didn't work? Right, because a lot of times when the stock market drives the stock to zero, it's because the company sucks and it's going to fail. Right. And so that's the other side of it. Right? There's no substitute for the thing.

[01:19:25.720] - Speaker 1
Are there ever times when the market loses faith in a company and it goes to zero, but the company still has value, and then it comes out back, out of the ashes and reinvents itself.

[01:19:39.310] - Speaker 2
Yeah. So our company. So our company, which loudcloud. Sorry, company, Ben. I started in 99. We went public in 2001, and then by 2003, our market capitalization of our stock was half the amount of cash that we had in the bank. Right. And so had we just simply liquidated the company and given the cash back, we would have made twice your money on the stock. And so what the market basically said was, yes, these guys have what the market was telling us. The message implicit in the price was, these guys suck so bad that even though they have this cash in the bank, they're just going to burn the cash and there's not going to be anything left to show for it. And then actually, Ben gets most of the credit. He was running the company. He turned it around, and then we ended up selling, I think the stock went up 40 x off the bottom. We sold the company for 40 x that amount. And, yeah, that was sort of a quote, unquote, turnaround. Look, Steve Jobs, Apple. So when Steve took Apple over in 97, when he came back, Apple had less than 90 days of cash in the bank.

[01:20:36.890] - Speaker 2
They were about to go bankrupt. That's how bad it was in 2009. I had a chart I was carrying around in my pocket all through 2009, 2010, when we were starting. When we were starting the firm. And I think Apple was trading at. I think they bottomed out at a price earnings ratio of like six. And what that basically means, a price earnings ratio of six. Basically, it's like what a steel mill trades at if it's about to go out of business. It's like trading for the liquidation value of the plant, equipment. It's a super low. It's basically the market hates you and thinks you're an idiot kind of thing. And this was like, right when the iPhone was taking off. Right? And there's a loose relationship between PE ratio and growth rate. We're roughly speaking, pe ratio and growth rate should be about the same. And so if a company is growing 10%, if it's growing earnings 10% a year, it should have a PE of about ten. It's sort of a loose relationship. And Apple had a phase there where the PE was six and the growth rate was like 40%, and then in some periods through there, as high as 80%.

[01:21:31.200] - Speaker 2
And so it was like, undervalued by, like a factor of ten just on basic math.

[01:21:35.320] - Speaker 1
And it was obvious to see that.

[01:21:36.880] - Speaker 2
Well, look, I wasn't running public money. I didn't put money where my mouth was. I gave a lot of interviews at the time where I pulled out this chart, because the point I was not trying to make stock call. The point I was making is everybody hates tech, irrationally. Like, if a financial crisis, like everybody.

[01:21:49.150] - Speaker 1
Got negative about this was after the.com.

[01:21:52.170] - Speaker 2
Well, it happened twice, so it happened after 2000. So what happened was the 2000 crash was like a real tech crash, and tech really fell apart. And there was like actually, a lot of carnage and a lot of companies went under. And then what everybody thought would happen was the global financial cris of 2008 would cause that to happen again. But it didn't. But they thought it was going to.

[01:22:09.770] - Speaker 1
So they acted like they acted as.

[01:22:11.290] - Speaker 2
If it would, and they traded the stocks as if that was what was about to happen. And so basically, 2008 to 2011, 2012 was just this extreme level of irrational hate and fear. And again, it's not like a super genius thing to be able to say looking, because you're looking at it, you're like, well, I don't know, this iPhone seems like, it seems like they're going to sell a lot of these things, right? And the same thing. Google was growing super fast, Facebook was growing super fast, but the world at large had just gone negative. Well, there's this famous thing in the metaphor for the stock market is this famous thing they say, think about the stock market as a person named Mr. Market, and he's like full on clinically manic depressive, right? And there's just like certain times that Mr. Market is just euphoric about everything, and there are certain times when he is just terminally depressed about everything. And then we all collectively are Mr. Market, right? So it's a group psychology thing. And so it's very hard to be a participant in the world and not get pulled into the group psychology.

[01:23:00.290] - Speaker 2
But as a consequence, the market goes through these wild swings, and it does regularly go through periods where people are just irrationally negative. And then, of course, then it's like, okay, you read the investor textbooks and it's like, well, that's when you buy the stocks. And it's like, well, yes, but that's when everybody's in a horrible mood and anybody who buys these things looks like a complete idiot because everybody knows that they're all going to go out of business. And so you talked about the consequences of being public. This is one of the consequences of being public is your companies get caught up in this and you feel it on a daily basis in a way that you might not.

[01:23:29.320] - Speaker 1
If you're, you could be in a tech company that's not public and you're just looking at your bottom line and everything's fine and, you know, your business is doing well. Whereas another, the same company, public all of a sudden gets caught up in this wave of things crashing and you crash with them, but nothing has changed in your company.

[01:23:46.430] - Speaker 2
That's right. Well, this goes to this relationship between the sort of metrics and management, right? And so there's this whole thing in management, which is you manage what you can measure, right? And so if you have a number that you can optimize on, you tend to optimize on that and you tend to run your company around that. It's the same thing politicians do with polls, right? I've got a poll number, and I'm just going to try to try to optimize around that. Now, is that the optimal way that people are actually going to vote? Like, who knows? But that's what you've got. You've probably seen this in political speeches. Have you seen this in politics? Do this on tv or the political speeches or debates. And they'll have this thing where they'll have a focus group and they'll have a dial that they can go to, like 100% negative, 100% positive. And then there'll be these red and blue lines and it shows word by word, it shows the mood of this focus group watching the thing. And so it's like a stock price, right, for every word coming out of a politician's mouth. And so if you're a politician, do you use that as a tool to try to optimize every single word coming out of your mouth and basically become the master of the craft of political speech giving?

[01:24:38.700] - Speaker 2
Or do you say, well, that's crazy. If I get wrapped up in that psychology, I'm going to drive myself nuts and I'm going to end up being incredibly unauthentic and I'm just going to be like a pure opportunist. And yes, it's the same thing with the stock prices.

[01:24:51.850] - Speaker 1
You read a lot of history. Is this just out of passion, or do you see some other use in understanding the past?

[01:24:59.830] - Speaker 2
It's a desperate attempt to predict the future. So, look, for 30 years, I've been doing this now for 30 years, starting companies or funding them statistically with what I do. It's like a 50% success rate, 50% failure rate, basically, which is pretty good, actually. Which is pretty good. It's pretty.

[01:25:18.030] - Speaker 1
Remarkably good.

[01:25:18.970] - Speaker 2
Well, it's pretty good. It's pretty good. I mean, it feels terrible. It feels awful. It's like your business. I mean, it's like your business, too. It's like sometimes the elbow 50% is remarkable. Yeah. Well, for baseball, it's great. There are other fields for test taking. It's terrible, right? Like driving on PCH. You got to score 100%, right? It depends. Here's another thing.

[01:25:41.520] - Speaker 1
But you're betting on things that are one in a million things.

[01:25:45.110] - Speaker 2
Well, yeah, let's say one in 1000 or something.

[01:25:48.260] - Speaker 1
Okay, one in 1000 things. 50% is really good.

[01:25:51.860] - Speaker 2
Yes. And just like in your business, the upside on the winners is bigger than the downside on the losers, right? And so if you have asymmetric upside on the winners and contain downside on the losers, then 50% does well over time. But the failures are just always horrible statistically. You can know that intellectually. You can know that emotionally, every failure hurts tremendously and it's wrapped up with people. So these are people that you care about. Right. And when one of our companies fails, it's not going to take our firm down because of the 50 50 thing. And our investors understand that. But it's a founder who has poured five. I just reaged out a company. This guy's poured five years into this, right? And it's been a big part of his life. And some of these people bounce back and they go and do other things. Other people just like, at some point, they're just like, I can't take it anymore. And then.

[01:26:37.540] - Speaker 1
But not everything works.

[01:26:38.850] - Speaker 2
Not everything works. Exactly.

[01:26:40.420] - Speaker 1
That's real.

[01:26:41.320] - Speaker 2
Yes, very much so. Right. And then there's another thing in tech, in venture called the Babe Ruth effect, which is the home run hitters strike out more often, and so the people who are really trying to do something new and radical actually fail at a.

[01:26:56.060] - Speaker 1
Higher rate, which is usually in for the fencing. It makes sense.

[01:26:58.730] - Speaker 2
That's right. Predicting the future of these things is absolutely impossible. Like that said, like, boy, I sure wish that I could. And so how do you ever possibly predict the future? And I do think there's some wisdom that comes from understanding, in particular the human dynamics. I think people have changed. I'm not actually a believer that we're the same people we were 100 or 1000 years ago. I think actually the people themselves might be changing, but in a lot of ways. But look, there are constants to human psychology, sociology, behavior of human beings and crowds. There are cycles in history of different kinds. And so at least in the past, you can kind of go back. And the risk of reading history is always that, you know the outcome, and so the outcomes look inevitable after the fact. But if you can kind of get yourself away from that, and if you can, especially the history works that I really like are either contemporary accounts of what it was like in that moment to actually experience that, or really the best historians are very good at recreating what it actually felt like to be there when it was all very uncertain.

[01:27:55.830] - Speaker 2
And then, look, there's also just a lot of tools you can just learn. There have been a lot of great people who have navigated through very difficult situations. Like, how did they do it? What's the toolkit? So, yeah, so it's a desperate reach into the past to try to learn whatever lessons they have to give me.

[01:28:08.530] - Speaker 1
Can you think of an example where something you learned from reading history impacted a real world decision that you made in the present?

[01:28:15.920] - Speaker 2
Well, look, I would just say, look, rallying people after disaster, right? Which is like, okay, there's been a catastrophe at a company. Like, okay, now you've got to recoher the team how you do that. And how do you do that? Well, you got to get up and talk to them. Okay, well, how do you do that? Well, how did Churchill do that? Right.

[01:28:29.960] - Speaker 1
That's a great idea.

[01:28:30.890] - Speaker 2
Yeah. That kind of thing works really well. And look, these are things that most people have not done in a lot of cases. And so being able to learn from somebody know the best of history is this incredible intellectual conversation across brilliant people over time who have kind of learned from each other basically by reading.

[01:28:48.420] - Speaker 1
Are the top vcs more of a group of colleagues and friends or rivals and enemies?

[01:28:53.130] - Speaker 2
Both coopetition, as we like to say. So we probably work together more than we compete. And the reason is because most successful companies raise from multiple vcs over time across multiple rounds. And so we end up on boards together and working with companies. But we do compete head on for deals and those competitions, we can punch each other in the nose pretty hard. We're in one of those right now, and we're going to try to punch in the firm in the nose as hard as we can. And so that happens. And then I think it's like any business. It's like, actually the movie business down here is famous for it, or music probably is also, which is you do end up with grudges. You do end up with two prominent figures who really hate each other. And it's like, well, 20 years ago, one of them said something in a meeting. I've got my list. Ben doesn't hold grudges. Ben's great at not holding grudges. I hold grudges, and Ben's wife holds grudges. And so when Felicia and I get together, we're like the Anya Stark character in Game of Thrones, where every night we recite the list of all the people that we're going to at some point.

[01:29:54.710] - Speaker 2
Yeah. And Ben's kind of always on me on this, is like, maybe you should let some of these things go. And I'm like, well, no, actually they're quite motivating. I'll tell you one thing that gets me out of bed in the morning is the opportunity to really stick it to somebody who I feel like did something wrong 20 years ago.

[01:30:11.450] - Speaker 1
That's unbelievable.

[01:30:12.530] - Speaker 2
So I like my grudges. Okay? They're very close. They're very important to me.

[01:30:16.590] - Speaker 1
Do all the vcs do the same thing, or does each house have a particular style or strength?

[01:30:21.500] - Speaker 2
I would say that the commonalities are there's a few universals, which is basically. And it's sort of this triangle. It's basically team, product and market is what you keep coming back to. So are the people really good? Are they building a product that people want? And then is there a market that they can sell it to? And it's sort of the most simple form of the whole thing. And those probably are. Those were the most important things 50 years ago. Those are probably the most important things 500 years ago. By the way, there's a long history of vc that predates all of tech, which we could talk about if you want, but tell me about it. So Christopher Columbus shows up in the, what is it? The court of Queen Isabella, and he's got this crazy idea to discover whatever it was, the new route to India, and he needs x whatever spanish pesos at the time, or whatever it was, to be able to get off the boats like he was making a venture. Pitch contained. Downside. What's the worst thing that can happen is he burns all the money and the ship sink and everybody dies unconstrained.

[01:31:10.620] - Speaker 2
Upside. Like, what if he discovers the new world, right? And then, of course, survivorship bias. We remember that story because it worked. We don't remember the thousand others that failed. Right. So he was raising venture capital. There's a famous story, JPMorgan was. JPMorgan was an investment banker who mostly dealt with debt for building out big things like railroads. But he sort of dabbled in venture on the side. And he was a. This is like 120 years ago now. He was Thomas Edison's first investor for indoor lighting.

[01:31:37.360] - Speaker 1
Wow.

[01:31:38.020] - Speaker 2
And so he wrote Thomas Edison a check for the new lighting business. And the first indoor lighting system, electric. Indoor lights, were installed in Jacob Morgan's famous library in New York by Thomas Edison personally. And then three weeks later, they caught on fire and burned his library down. And then he paid Thomas Edison to do it again, rebuilt the library and put in lighting. And it worked. So he did it. The one that I find so fascinating is actually the whaling industry. So the structure of the modern venture capital industry is basically very similar to how whaling expeditions were funded in the 16 hundreds, like off the coast of Maine. And it was a very similar kind of thing where you had basically these captains who were the entrepreneurs, and they would put together a business plan for a boat and a crew, and they'd actually have an equity model for how the crew members get paid. They'd get paid basically a portion of the whale, and then they would come and pitch, basically the people who financed whaling journeys, the VCs, at the time, and the VCs were special in evaluating the captain and the boat and the plan.

[01:32:36.950] - Speaker 2
The captain was a specialist in figuring out questions like, well, do we go to the place where there have been lots of whales spotted, but those are the places other people are going to be at? Or do we go to this other place that we think nobody's discovered yet, and then, like a third of the boats never came back? And then there's this concept. The way that vcs get paid is there's this concept called carry. The term is carried interest. And then the sort of colloquialism is carry. And the idea is basically, it's like 20% of profits for the ones that work. You kind of make 20% of the profits or some number like that. And it's called carried interest. And the reason it's called carried interest is because that's how the captains got paid on the successful whaling expeditions. And it was literally the percentage of the whale meat and fat that the ship could carry is where the term carry comes from. And so on a successful voyage, the captain would get 20% of the whale.

[01:33:25.800] - Speaker 1
It's interesting, both examples you gave are about light, because the reason the whaling was such an important part was that's what was the fuel for the light before the electricity.

[01:33:35.550] - Speaker 2
Yes. Very fundamental. Yes, exactly.

[01:33:38.780] - Speaker 1
That's amazing.

[01:33:39.710] - Speaker 2
Exactly. So, look, it's always been basically what you find. You have this kind of entrepreneurial personality, and it might be the captain or it might be the founder or whatever. Or by the way, it's a movie producer, right. You have an entrepreneur or personality who has a vision, but they're not going to be able to realize it on their own. They're going to need to be able to gather resources to do it, and then they're going to need money and partners to be able to do that. And then there's going to be some evaluation process. There's going to be some professional class of people who are trying to evaluate that. They're going to be operating in this domain where they're wrong a lot of the time, but the successes make up for it. And so it's kind of this universal pattern and I think it's been running actually for quite a long time. The best guess would be this will run forever, runs for thousands of years. The kinds of startups that you'll have in 1000 years will be totally different than what we have now, but they'll still have the model, they'll still have that same property, the unknownness of it.

[01:34:29.420] - Speaker 2
And look, they'll be reading histories of what we did and being like, wow, I hope that we can learn from all their failures, right. It'll be the same cycle. There's one more thing is like people get mad, you find interesting about, because it's become very popular to kind of get mad at venture capitalists right now or kind of be mad about this whole process, or you mentioned like the move fast break things get mad about disruption. It's like, well, it's like fundamentally, do you want there to be new things in the world? Because if you want there to be new things in the world, they're not going to show up predictably from well mannered people who are going to behave well in every aspect of their lives. And then the new thing is not going to disrupt or change anything. That's not what happens. Change doesn't enter in this kind of peaceful calm.

[01:35:07.720] - Speaker 1
It's always a revolution.

[01:35:09.360] - Speaker 2
Exactly. Right. And if it's not, it's not change. Right. And so would you really prefer to critics, I said, would you really prefer to live in a world of total stagnation where nothing changes? Is that really what you want? And by the way, what do you think would happen in that world? Like what would the politics be like? What would society be like? I think basically everybody would hate that. But to live in the world in which the revolutions happen, you need to have a perspective. And it's easy to say this and it's hard to do, but you need to have a perspective that says, yeah, these revolutions like, look, they're going to be wild, right? They're going to be wild, they're going to upset a lot of things. They're going to upset a lot of people. They're going to upset power relationships in society, hierarchies, gatekeepers are going to be furious, right? Like old incumbents are going to be furious, governments are going to get freaked. All that is going to happen. But it is a direct consequence of the fact that it is actually change dynamism happening. Nobody has ever figured out how to do this in a way that makes everybody happy.

[01:35:59.460] - Speaker 2
It's just a question of whether it happens at all. And by the way, there are many societies in which historically this didn't happen. And what we know of those societies is they basically just died.

[01:36:07.420] - Speaker 1
If you look at the Fortune 500 over history, how much change has it had over what period and what are the inflection points?

[01:36:18.410] - Speaker 2
It changes a fair amount, although a lot of the changes have to do with mergers, like when two big companies merge. Has anything really changed? I'll just give you an example. Time Warner here in town, Time Warner Discovery have merged, and it's a sort of a high drama in the media business right now. What's going to happen to that? But it's like Warner Bros. Studio has been in business for 100 years. If Warner Bros. Discovery works, it'll still be Warner Brothers Discovery in 20 years. If it doesn't work, it'll get bought. And, I don't know, maybe Apple buys it and then Apple will run the Warner Bros. Studio for a while, and then at some point, they'll get tired of being in the media business and they'll sell it to, I don't know, Disney, but it's still the Warner Brothers studio, right? And so I think in big company land, there's a lot of what looks like drama in reality, it's just kind of assets as trading cards being traded around. Are the movies any different than they were ten or 20 years ago? Maybe a little bit, but not really. So I think a lot of the change is actually not real change.

[01:37:09.520] - Speaker 2
Having said that, look, the sectors change a lot, right? And so, look, when there's, like, build out happening in a sector, I mean, when railroads were new, they were most of the stock market, right?

[01:37:18.160] - Speaker 1
Well, pre tech, it feels like it didn't change so much.

[01:37:21.520] - Speaker 2
Well, but we forget what was new at the time, right? So from the 20s through the were new, right? And so the car companies became, the car companies were not big in the. They become huge and dominant by the 50s, GE is Edison, basically, like, you had to invent all that stuff before it existed. Ge wasn't a big company then. It was. And actually, this is one of the things in history, one of the things that's useful in history, which is most new industries look like tech in the beginning. So example, the car industry, actually, it's actually funny. The car industry actually didn't grow up originally in Detroit. It grew up in Cleveland. And the stories of the first 20 years of the car industry basically are these hobbyists and tinkerers and entrepreneurs and garages in Cleveland in, like, 18 9019, 1910, trying desperately to figure out how to get these car things to work. Yeah, right. And by the way, the car was greeted with, like, an enormous amount of fear. Like, people were not happy about the car. And a lot of states had these. One of my favorite stories about people reacting to tech is a lot of states, actually, in the US, did not want cars to be on the roads, because what was on the roads was horses and people and cars were dangerous and scary and loud, and they freaked out the horses.

[01:38:21.370] - Speaker 2
And so a bunch of states actually had what they call red flag laws in that time period where if you. You could have a car, but you needed to have the car, the car would break down all the time. So you had the car, you had your mechanic that would go on the car ride with you. The car would only go, like, 20 miles an hour, which was, like, super fast because it was faster than a horse. And then you had to hire a third. You had to hire a third guy to be 200 yards in front of the car with a red flag waving ahead of time so that the horses would know, the riders on horses would know to pull to one side. And then the horse lobby got really mad about this. And so they passed a law in Pennsylvania where they said if a car and a horse encounter each other on the road, the owner of the car has to stop the car, disassemble the car into pieces, transport the pieces, and hide them behind the nearest hay bale so as not to freak out the. So my point being, like, what was that?

[01:39:07.680] - Speaker 2
That was the tech industry. That was the disruptive tech industry of that time. The personalities of the people. I'll give an example. The car industry. GM is like this giant company, 100 years old. There was this guy, Alfred Sloan, who was, like, the famous CEO of the whole thing, who built it. But actually, there was a guy named Billy Durant, who was actually the founder early on. Before that, he was like the Elon character, and he basically. And his name is lost to history for whatever reason, but he basically created the modern car industry. And you read the stories of him, and it's just like reading about jobs or Larry Page or Sam Alman or he's one of these people. And so I think these patterns are actually older patterns.

[01:39:44.090] - Speaker 1
Who do you view as your biggest competitor?

[01:39:48.640] - Speaker 2
The answer to this always sounds incredibly cheesy, but it actually is true, which is. It's me, by far. This is the speech I give inside our firm, which I very much believe, and I give the speech to myself all the time, which is like, look, if we screw this up, it's our fault. It's suicide, not homicide. And it's basically, it's because we were not as good as we needed to be. We screwed it up. There was a way to do it, and we blew it. And maybe we blew it out of ignorance, but probably we blew it out of arrogance and ego and hubris. And then I think for what we do, it is fundamentally a people business more than a money business. That's interesting, being in a people business, like every conversation matters and you're dealing with people's lives. This is the speech I give internally, is you're dealing with people's lives. And when you're dealing with people's lives, you have to talk, you have to be very serious about what you say, and you have to be very careful about the consequences of what you say and really think hard about every conversation.

[01:40:41.640] - Speaker 2
And you know how it is. It's like, okay, it's year we're entering year 15, I've had 400,000 conversations. The 400,000 at first conversations could go really wrong. Right. If I'm not, like, on the ball. And I would say I'm much more worried about that than I am about somebody coming in and stealing our lunch money.

[01:41:00.440] - Speaker 1
Other than financial returns, how do you know if you're good at your job.

[01:41:06.760] - Speaker 2
At that point? I think it's basically, what are people saying about you? Yeah. Look, the thing is, though, look, there's a paradox at the heart of that, which is like, it's really easy to get people to like you just by always telling them that they're smart and they're good and that their ideas are good, and we don't do that. And so the trick is, do they still like you and trust you and respect you after you have spent telling the truth and you're just telling them the truth. Exactly.

[01:41:26.750] - Speaker 1
And it's your job when you tell somebody the truth and you're giving them good news, they can trust the good news because they know when you had bad news, you gave them the bad news.

[01:41:39.870] - Speaker 2
That's right.

[01:41:40.240] - Speaker 1
If you just, everything is always rosy, it means nothing.

[01:41:43.700] - Speaker 2
Yeah, that's right.

[01:41:44.880] - Speaker 1
It's the bad news that gives you credibility.

[01:41:47.020] - Speaker 2
Yeah, that's right. But it's hard because. Absolutely. People are under a lot of pressure and probably happens to do. They get upset in the moment and then maybe a couple of days later they're like, actually, that was a pretty good look, if they trust you, right? Another thing that Ben and I talk about a lot, Ben says this a lot, is he says, trust and communication are opposites. Everybody thinks they're the same thing. They're not. If I trust you, we don't need to communicate that much because you know that I have your best interest in go. Ben and I have this. Ben and I could go off and not talk for three months and we would come back. We'd have the exact same relationship on the other side, because I have so much trust in him that I would know that whatever decisions he's making are in my best interest. Whereas if you don't trust somebody, you really got to communicate. You've got to cross check everything they say and roll them and interrogate them. And so I think the best relationships are. This is what you try to develop is like, actually, look, I'm going to tell you some things you're really not going to like, I'm doing that because I care.

[01:42:39.660] - Speaker 2
I'm doing that because I am delivered.

[01:42:40.910] - Speaker 1
And you're also doing that because you're being true to yourself in saying, this is who I am. This is how I see it, which is really valuable.

[01:42:51.080] - Speaker 2
And look, I'm not going to step in and run your company. Like, I'm not going to fire you. I'm not going to replace, like, this is not the thing that's going to make or break anything. I'm just going to try to help you get to the truth and then have the trust relationship over time where you believe that that's what I'm trying to do.

[01:43:05.270] - Speaker 1
When you were in school in Illinois, there was a supercomputer.

[01:43:09.270] - Speaker 2
Yeah.

[01:43:10.180] - Speaker 1
How many supercomputers were there in the world at that point?

[01:43:14.100] - Speaker 2
A few dozen, maybe total. Most of them would have been in government labs. Those were the kinds of supercomputers used for nuclear weapons development.

[01:43:23.220] - Speaker 1
Why was it there?

[01:43:24.150] - Speaker 2
Cryptography. So the government would have had a bunch, but not really anywhere else. I give the government a fair amount of credit for that one. So remember, Al Gore got in trouble years later for saying that he invested the Internet. And of course, that's not what he said. And what he said was he had played a role in the Senate in creating the Internet. And of course, that was actually true. So that whole thing was actually a smear the whole time. That was actually true. And specifically what he did was he sponsored these hills in the early 80s, which did two things. Number one is they created what were called the national supercomputing centers, and that was for universities that were given basically these grants to buy these very expensive and rare kind of things at the time, and to give you a sense of how rare and special these things were in those days, we had one of the computers at Illinois. They literally built a building for the computer, and the computer was so big that they built the building, and they left the roof open, and they lowered, after the building was built, they lowered the computer by a crane who made the computer.

[01:44:20.820] - Speaker 2
It actually was, incredibly, a company in Wisconsin. So there was a company called Cray. There was a guy named Seymour Cray who did a lot of it. And then there was this company called thinking machines. And there's this guy, Danny Hillis, who you might have encountered at some point. So they were these kind of know, kind of special entrepreneurs who were good at this. They became sort of know. You've seen them in movies. One of, they were so expensive, this is like $25 to $50 million and up. And this was 40 years ago. So this is like equivalent of, like 100 million or something today per unit. But one of the things they really value design. And so they actually looked really cool, and they were water cooled. Heat is always a big problem with any kind of advanced computer. And so they did what's called water cooling. So they would have these very elaborate water cooling systems. There's a guy who actually bought one of these years later off of eBay and converted the water cooling system into a beer keg, the world's most expensive beer tap. But they were like works of art.

[01:45:15.080] - Speaker 2
And so you've seen them in different movies over the years. Yeah. So they were just, like very, very rare, exotic. Anyway, so the government funded these four centers at these four state universities because these computers made new kinds of science possible. So these were used for different astronomy, astrophysics, decoding the secrets of the universe stuff, and then a lot of biomedical, protein folding, developing new drugs, curing cancer kinds of research. So it was sort of becoming key to a lot of areas of science. And then they had enough money to put for these centers in place, but they wanted to give scientists all over the country access to the computers. And to do that, they needed a high speed network so people could log in remotely. And so they funded what was called the NSF net, National Science Foundation Network, which basically was the Internet. It was sort of the Internet pre. The. My big stroke of luck was, it turned out Illinois, where I went, was a top computer science school at the time, and still is. And they were one of these four centers. And so they just had this did.

[01:46:12.880] - Speaker 1
You go there knowing that was there?

[01:46:14.380] - Speaker 2
I did, yeah, I did. I didn't know that I would play any sort of inform. I didn't know how it would be.

[01:46:20.400] - Speaker 1
To me, but seeked it out.

[01:46:21.870] - Speaker 2
Yeah, well, I knew what was happening. This was in the late eighty s, and so, yeah, it was big enough. The computer industry was being covered in newspapers and magazines at that time. There were articles written about this was how we experienced it at the time, but I knew it existed.

[01:46:38.420] - Speaker 1
Did you have a home computer at that time?

[01:46:40.470] - Speaker 2
Yeah, although when I got to college in 89, the home computers in those days weren't actually useful in an academic setting. They weren't powerful enough.

[01:46:48.680] - Speaker 1
But you had experience on a computer before you went to college?

[01:46:51.390] - Speaker 2
Yeah, but on really simple computers. So I sort of went from working on computers that cost like $400 to working on computers that cost like $40,000 in one step. And so at that time, it was a completely different kind of thing. So the computers that I worked on at college were just like I said, they were like 40, 50, $60,000 baseline cost just to have something on a desk. And then these supercomputers were, like I said, 25, $50 million. So these were not one of the advantages of being at a UIUC at the time was that they had this equipment. But all of my work was not done in my dorm room. It was all done in the computer lab with fluorescent lighting and drop ceilings and all this stuff, because all this hardware was like, super exotic. These days, that doesn't exist as much. Your phone today is the equivalent power of that supercomputer that I worked on. Your laptop is more powerful than that. And so today that doesn't happen if you just have a modern laptop. You have basically a full fledged computer that you could do almost anything on. And then there's this cloud idea where you've got these grids of millions of computers up in the sky.

[01:47:51.920] - Speaker 2
If you need more power, I don't know, the romance or whatever of this exotic thing in a building being taken care of by people in white lab coats. Those days are kind of over in.

[01:48:03.600] - Speaker 1
Terms of what the supercomputer was capable of. How does that compare to your laptop at home now?

[01:48:09.200] - Speaker 2
Yeah, so your laptop at home. My laptop right now is a MacBook. I think it's an m two or m three processor. And I haven't checked, but it's probably somewhere between ten to 100 times more powerful than that supercomputer at that time. Well, and in fact, you could ask a cynical question on this, actually, or I could, which is if those computers in those days were so rare and exotic and they were able to be used for things like decoding the secrets of black holes, and everybody has a laptop that does that today. Where's all the science? Where's all the creativity? Which I think is actually a question, a very excellent question. But, yeah, look, in theory, everybody has on their desk today, and increasingly just in their pocket, they have the ability to basically do what in those days, we would have considered to be absolutely breakthrough scientific work, by the way, artistic work, by the way. Another thing that happened at Illinois, this is kind of lost history. Illinois was the. There were a set of universities, and Illinois was one of them because of this, that actually developed basically what we now think of as 3d computer graphics and ultimately developed what became CGI in the movie industry and the whole idea of computer graphic design.

[01:49:07.450] - Speaker 2
And so when you see a rendered tornado or whatever in a Hollywood blockbuster, a lot of that is actually techniques that were actually developed also at Illinois and a few other places like that at that time. And the supercomputers originally, it was so hard to do computer graphics that were so processor intensive that it was only those supercomputers that could do that back then. So that was another thing that actually was invented at that time.

[01:49:29.550] - Speaker 1
What was Mosaic?

[01:49:30.880] - Speaker 2
So basically, I ended up at Illinois. I ended up working at this supercomputing center after a few other things. And then they had a group in that supercomputing center that was building the software tools to make it possible for people to use these computers. And in particular, remember what I said, the link between these big centralized computers and then the Internet. Basically, the purpose of the Internet, as funded by the government, was for scientists to be able to access these computers remotely. But then there needed to be a new kind of software tool that was built to actually make that possible. And so there was SDG, the software development group at Illinois that was in business to do that, had government grants to build that software. And so Mosaic was a project that basically a group of us did at that group. And its nominal purpose funded by the government. And its nominal purpose was, and by the way, not funded for a lot. I was making $6.25 an hour. So it was not a lot of tax money. But, yeah, the purpose of it was basically remote scientific work. So the original purpose of it nominally was a scientist who wants to basically publish information, have other scientists be able to read it online.

[01:50:33.900] - Speaker 2
Mosaic was the browser front end on being able to do that. And then we also had a cert. We had basically one of the first web servers that made it possible to store and host things. And so that was the nominal purpose. But then because it was government funded, we actually had to give it away. We're not allowed to make money on it. And so we released it as open source. And then the nascent Internet was starting to get big enough where there were people on it, downloading it and using it. And then they had ideas for other things that they wanted to use it for other than scientific papers. And then that led to the felt well of the creation of the web.

[01:51:04.270] - Speaker 1
When did you understood it could be used for more than scientific papers?

[01:51:08.320] - Speaker 2
Right up front. I don't even think this was like prescience or anything. It was just sort of obvious. It was just like, oh, the thing that just was immediately obvious was, oh, this could be used for newspapers, this could be used for magazines, this could be used for books, anything. Right.

[01:51:19.980] - Speaker 1
Music, it's a new communication tool.

[01:51:21.750] - Speaker 2
Yeah. And literally, I didn't build all this myself, but I worked on a lot of the early code for doing music online. I remember when we first figured out how to do music in the web browser. I remember how we first figured out how to do video in the web browser. And so I remember how when the Internet radio first started working, there was this project that we were not working on, but I knew the people working on it called MBone at the time, which is the first music broadcast thing. And so there were a set of us where it's just like, oh, it's just sort of obvious that this is going to be used for everything. It's a McLuhan thing. The content of each medium is the previous medium. The content of a movie is the stage play. Right. The content of the music video is the music track. And so it was the same thing here, except this is the one where it's going to be all of them. Right? And so I just thought that was obvious. A lot of us actually thought that was obvious. That said, there were a bunch of purists disagreed, and there was actually a big fight early on about whether there should be images in the web browser.

[01:52:14.440] - Speaker 2
Images and web documents.

[01:52:15.910] - Speaker 1
And the argument instead of just text.

[01:52:17.430] - Speaker 2
Instead of just text, because the argument was, I bet you can predict the argument, which was, if it's just text, it all has to be serious, where you introduce images and it gets frivolous, and then the frivolous will drown out the serious, and then everything will go to shit.

[01:52:28.710] - Speaker 1
Right?

[01:52:29.030] - Speaker 2
And I was like, that's what happened. Yeah. Well, a, that's what happened. And b, I'm glad that it did. Right. Like, who wants to live in a world where you don't have images? And by the way, there's a logical flaw. Right. Which is, it turns out there's a lot of shit text, too. So it's not. The text actually gets you. Guarantees you quality either. It's true. For better or for worse. I always bias in the side of openness and creativity. I want more experimentation in the world, not less. And so anytime anybody says, no, we need to constrain this, I'm like, yeah, no, we're not going to constrain. Absolutely. We're going to blow it out.

[01:52:56.940] - Speaker 1
You never know because you never know.

[01:52:58.320] - Speaker 2
That's right.

[01:52:58.700] - Speaker 1
Can't predict.

[01:52:59.320] - Speaker 2
Yeah, but you get with the bad, with the good, right? Okay, so we rolled out images in web pages. Guess where? What? Some of the first images that people put in web pages. Well, let's say dirty pictures.

[01:53:12.140] - Speaker 1
Adult content.

[01:53:13.160] - Speaker 2
Adult content. And so, as my eight year old would say, special parts. And by the way, it's a cliche that the Internet was used for porn first. That's not really the case. It was always kind of a march edge thing. But people did start to post adult stuff. And this is a government funded program at the time. And so this is actually the first free speech issue. This is the first trust and safety issue, which is my boss at the time said, well, you have to filter that stuff out. And I was like, filter what stuff out? And he's like, well, like nudity. And I'm like, how am I going to know which pictures have nudity in them? There's no way to do that. And he's like, well, you'll have develop an algorithm that detects nudity. And I'm like, what? Like, through what shapes? Booby detectors? Is that what you're asking me to make? And he's like, yeah, can't you do that? And I was like, no, I can't. And furthermore, I won't. And I just put my foot down. And I said, we're not going to build censorship into the web. And that had, I would say, potentially civilizational consequences.

[01:54:13.140] - Speaker 1
You're at mosaic. You're building what you're building. You could see a lot of things in the future, but how did you imagine the world in the future then versus how the world is now? What did you see? And what didn't you see first is.

[01:54:29.500] - Speaker 2
Like, look, the day job. There's this kind of presumption. Oppenheimer actually went into this a lot. There's this presumption that the people developing the technology are somehow in a position to know the consequences of its use. And I think that's actually untrue on several levels. And one of them is just a practical level, which is most of what I was doing was just trying to get code to work. So I had, like, a day job, which was all consuming. It was like 18 hours a day of just, like, writing software and trying to fix bugs in software. And so most of what I was doing, it's the old thing in art, which is when artists get together, they don't talk about art, they talk about where to buy the cheapest paint. So it's like that. Most of what I was doing was, like, mechanical, trying to just get the stuff to work that said, look, had you asked me then what I would have said was, look, I think this is going to be something that a lot of people are going to be able to use. And in those days, that was a very radical concept because people didn't have the computers to use it.

[01:55:13.820] - Speaker 2
They didn't have the network connections. There was no broadband, there was no mobile. Right? People didn't, weren't comfortable with computers in the same way. It wasn't clear that there would be any good. Who would ever publish any content. It was like an open question at that point. And so it was radical enough, I would say, at that time, to say, this is something a lot of people are going to use, and a lot of people are both going to publish content on the Internet, and a lot of people are going to, are going to consume it. And by the way, it's not just going to be fixed content. It's also going to be experiences and databases, and they're going to interact in different ways and chat and discuss things and so forth. We didn't have social networking, but we knew, like, we had chat boards and forums and stuff. So we knew there'd be a lot of communication, there'd be a lot of groups forming.

[01:55:50.820] - Speaker 1
Did you spend time on a lot of groups? What was that like?

[01:55:53.780] - Speaker 2
Oh, it was great. Well, in my world at that point, the dominant thing was what was called usenet, and the system was called usenet, and then the groups were called news groups, and they were basically, it's a bullion board system that ran across the Internet. And there was a period of about 1985 that predated me starting in 85 to about 1993. So I saw four years of it where it was like digital nirvana. It was like the smartest million people in the world were like talking about everything under the sun. And text, only text. You could embed images, you could attach images, but it was mostly.

[01:56:28.070] - Speaker 1
Mainly text.

[01:56:28.710] - Speaker 2
Mainly text.

[01:56:29.670] - Speaker 1
Would it be conversations or more like essays?

[01:56:32.150] - Speaker 2
Both. A lot of essays. Only like conversations around essays. And then there was a folder, there was a whole hierarchy, so you'd have all these different domains. And so some of them were technical conversations, but there were like lots of political conversations where lots of art and.

[01:56:43.390] - Speaker 1
You could find the topic you were interested in.

[01:56:45.160] - Speaker 2
Yeah. And you would pick the news group that had the topic you're interested in. Some of the news groups were unmoderated, so you could say anything. Some of them were moderated. They had a human who would kind of keep them under control.

[01:56:53.270] - Speaker 1
Similar to social media, really.

[01:56:54.810] - Speaker 2
It was basically. Right, it was the, er, form of social media. But what was fascinating about it in retrospect, it's a lost golden era that's been impossible to recapture since, which is it basically grew to be the million smartest people in the world with basically no idiots or assholes. Anybody, in theory, could be on it and anybody could, in theory, say anything they wanted. It just so happened that the only people who had access to it were like the best and brightest. And so there was no spam problem, there was no abuse problem, there were occasional flame wars, but there was nothing. There was no hate speech. And then the content quality was just incredibly high. And the communities that formed were like, incredibly high. And the trust level that formed was like incredibly high. People became very close, as they do across this, with people they never actually physically met. And it was like this nirvana of like, what if you could just have the millions of people connected to nobody else? And then of course, what happened was everybody else showed up. And there's this term in the Internet culture called eternal September.

[01:57:57.080] - Speaker 2
And so it's based on the fact that it was September 1993 is when AOL connected to Usenet for the first time. And all the AOL, the 25 million AOL users or whatever it was at the time, were able to be on Usenet and they just like, buried it. Shit. Just completely destroyed the quality, right. And just swabbed it. And then Usenet basically died in September of 1993 and never came back.

[01:58:17.790] - Speaker 1
All that stuff still online, can you find it?

[01:58:19.880] - Speaker 2
A lot of it is. So it's been preserved. There's a thing called Google groups. Google has a thing called Google groups and they have archives in Google groups of a lot of these original things. And for what kind of things you're interested in it would be what we're called the alt groups. Alt music. So if you go to Google groups, you could read like alt music discussions from like 1990 and I bet you would find them to be quite interesting. And so eternal September is sort of this idea that basically, now the Internet basically consists of September 1993 in perpetuity, which is like, no matter what good things there are, it's just going to get swamped with basically people with either dumb people or people with bad motivations. Anyway, so it was the shangri la of our experience.

[01:59:00.430] - Speaker 1
Are there ways to create gated communities online?

[01:59:04.110] - Speaker 2
Yeah, well, so there was another famous one of that era called the well, which was an Internet. It wasn't an Internet system, it was a bullshit board system. And it was. Stuart Brand ran it and I think it had a total at the peak of like 3000 people. And there were two tricks to how he did the well, one was, I think, if I recall correctly, I think he vetted all the new members. So it's like a club. And then two is he charged a membership fee. And so you had to kind of pass both of those hurdles to get in. And again, for many years, it was apparently really amazing. Spectacular, by the way. This is an idea that nobody's really cracked the code on this, but this is arguably like an undiscovered idea. It's a known idea that nobody's figured out how to implement, which is like, how would you recreate that kind of thing today?

[01:59:42.090] - Speaker 1
Because it sounds really great.

[01:59:43.710] - Speaker 2
Yeah, exactly right.

[01:59:44.500] - Speaker 1
And it sounds like we spend a lot of time scrolling through things we might rather not if we had that.

[01:59:50.430] - Speaker 2
More curated, but you have to be willing to violate the dominant conceit of our time, which is you have to be willing to say that not everybody's the same. Right. Generally, I'm a fan of, like I said, I'm a fan of openness. I don't like the idea of gating people by MyQ or anything else or social acceptability or whatever. But within the universal global village, yeah, I think it may just be that more people should start to carve out these more specialized areas. There are some. There are a few of these. There are mailing lists that are like this. There's often actually something that happens. Often a new social media product will first take off with being incredibly high quality to start. Well, Facebook was like this early on because Facebook started out just being Harvard kids and then when they expanded, they expanded to the top ten universities. And look, the kids at Harvard have lots of issues, but at least especially in those days like they were 20 years ago, things have changed, maybe even since then. But generally speaking, if you want a group of 5000 really bright young people, the people going to the top universities are a pretty good cross section.

[02:00:54.580] - Speaker 2
There's this thing which is, there's a pattern that we've all noticed, which is new social networks start. Well, a friend of mine puts it this way, which is the quality of any group can only decline over time because basically you only want to join groups that on average are better than you, right. You never want to downselect, you never want to deliberately join a group. That is. But it depends, well, it depends what the axis is. But generally speaking, you want. It's the Gresham marks. I don't want to be a member of a club that will take me. Right. Generally speaking, you want to go higher status by joining the group, not lowering your status by joining the group. And so I have this friend who argues that basically the thing with social networks is they're not technology platforms, they're groups, they're communities. And the thing is, on day one, they're the best they're ever going to be and then they will inevitably decline. But then there's a whole bunch of things you could do to try to basically arrest that decline side, but you have to grapple with the fact that it's going to start out as very best, which means the selection process of who you start with is incredibly important.

[02:01:52.250] - Speaker 2
And of course, the same thing is true of a company or any other kind of community. It's the same thing when you're planning parties. It's human dynamics. And so arguably there's like an unexplored design space for modern social networks that actually acknowledge that and didn't try to be everything to everybody and just tried to be specialized like that.

[02:02:07.980] - Speaker 1
I think it'd be nice for everybody to have the one that they want to belong to, to opt in. That sounds like a good look.

[02:02:15.620] - Speaker 2
You know, there are versions of. There are some people have this experience with Facebook groups, Twitter. If you use Twitter in the right way and you customize lists and you pay a lot of attention to who you follow, I've got a couple of Twitter lists that I think kind of count like this. And so you can back your way into it, but it's not, I mean, the eternal September has dominated for better or for worse. The openness has resulted in.

[02:02:36.550] - Speaker 1
How has writing code changed from when you were at school, when you were a code writer versus writing code today? Is it the same language? Could you do it now the same way you did it then.

[02:02:50.200] - Speaker 2
You could. Yes, you could. So all those tools still exist. Those languages still exist. So I wrote all my code in what was called a language called C. And C is sort of the native language of the operating system, Unix. It's one of the great kind of universal programming languages that people with deep technical expertise are expected to know how to do. It's an older kind of programming language in that the semantics of the language are very linked to the hardware of the chip. And so when you're programming c, you are directly talking to the underlying hardware. The classic thing is so chip, processor, and then there's memory. In C. You have to do what's called managing memory yourself. And so you allocate memory on the memory card. You fill it, you have to unallocate it. If you don't unallocate it properly, you get what's called a memory leak. The program runs, it gets slower and slower, and then it ultimately crashes. So you have to do all that.

[02:03:40.860] - Speaker 1
Sounds like a lot of work.

[02:03:41.800] - Speaker 2
It's a lot of work. And you end up in, I would say, communing very deeply with the machine. You have to really understand how the whole thing works, all the way down to what we call the bare metal, the actual physical silicon. Like, you have to really kind of understand that.

[02:03:53.280] - Speaker 1
It really sounds like a really good tool to learn either way, whether you stay that way or not.

[02:04:00.560] - Speaker 2
So the thing for a very long time, I think, and I had the beneficiary of this, I think the thing for a very long time that made a computer programmer really good was when they understood every aspect of how the machine worked, all the way up to the graphics and everything, but then all the way down to the chips and the metal and the design. And I spent just as much time in school learning about how to make chips and all this stuff as I did trying to make mean software because it was like an integrated system. I think there's a critique, which I think is a valid critique, which is probably in the last ten or 20 years, a lot of programmers now become actually very good programmers, but they never actually learned how to do that. And that's fine for a lot of things. But anytime things get complicated where you need things to be super fast or you need them to be very secure, or you need them to get scale to get really big, you do tend to need to bring in somebody who understands kind of what we call the full stack, the whole set of things that's not as common anymore.

[02:04:49.060] - Speaker 2
So the overall trend that's happened in the last 30 years, 40 years, is most programmers don't do what I was doing. They're not programming at the bare metal the way I was. Mostly what they're doing is higher level, they call abstractions. And so they're in these languages that languages like kids learn in school, where they're much easier to code in. You don't have to worry about any of the hardware, the memory, whatever, these so called scripting languages, Python as an example, you'll hear where Javascript, where it's easier, it's easier to get into. They're more powerful languages. The language does more for you. So you can write like a new app faster than you could in the old days, but you don't have that connection to the machine anymore. That was the big trend for the last 40 years. And then it just changed again, basically last year. And this change last year, this year is the biggest change that any of us have ever seen, which is the AI. The shift to programming with an AI, and in particular, basically the model that people have right now is one of either two things. Either you just tell the AI what code you want and it makes it for you, which works for examples today, but doesn't work for building full programs yet, although it will at some point.

[02:05:53.320] - Speaker 2
But the thing that programmers do today is they have this model called a copilot, AI copilot, right? And so the new model of programming is you're writing code on the left half of your window, and then you've got an AI chatbot UI interface on the right side of the window. And as you write code, the chatbot is inspecting your code and talking to you about it, and then you can ask it questions, right? And so if you're writing code, you do a typo or whatever, a bug, and the AI can continuously analyze the code as rewriting it. You can say, oh, that was a mistake, you should fix that right now. And you're just like, wow, that's great. I don't have to discover that the hard way later. That's great, right? Or you could say, like, here's, I have this code that's going to render something. I need it to be faster. How should I performance optimize it? And the AI will say, well, here's how you do it, and here's how I, the AI would rewrite it. Or you can tell the AI to make changes, right? And so it's like, I want everything to be, I don't know, you want to do a translation from English to Spanish.

[02:06:46.160] - Speaker 2
And you can use the AI to find all the places where you have an english language word and you can swap into the spanish translation and the AI could do that for you. And so it's like it's copilot, it's like a super assistant kind of thing. And so that's like a radical change. And so the coders that are using that versus not using that today, they're pretty much universally kind of saying that's a night and day kind of thing. And then that's just with today's AI. And what everybody expects is the ais of the future are going to get much more sophisticated. And so sort of what the AI people basically say is in five years or ten years, you're not even going to have that. What you're instead going to have is like the equivalent of 1000 AI programmers working for you. And so you're not even going to be writing code yourself. You're just going to be basically managing the ais to write the code. And you can basically say go off and do all this design and coding and graphics and whatever it is, and you basically hand out assignments and then the ais go off and do it and they report back.

[02:07:36.600] - Speaker 2
And then you kind of oversee the entire process. If that vision plays out, that's a complete revolution. Right. And then the way to think about that is think about this in terms of productivity. How much software functionality can one person make in an hour or a day or a year? And what all of these changes mean is sort of an explosion of productivity. You just get to make a lot more code.

[02:07:55.990] - Speaker 1
If AI learns to code, that really changes things.

[02:07:58.870] - Speaker 2
Yes, exactly. Right. Well, and then that raises all these questions that you get into on all AI topics, which is like, okay, well then is AI going to get good at coding AI? Right? And so this gets into all the AI topics, which we could talk about, but the reason I bring it up is because it's a very fertile moment for our entire world of technology, rethinking how all this stuff works. This might be the biggest change that any of us have ever seen.

[02:08:22.500] - Speaker 1
What's different about AI? Why is it so different?

[02:08:25.570] - Speaker 2
It's different because it's a very fascinating story. So the idea of the computer goes back prevent as we know it. The computer was invented in the 1940s, during World War II to basically crack nazi and japanese codes by primarily the US and english computer scientists, people like Alan Turing. And that's the true story. That's conventional story. That's the true story. But the ideas are older than that, the ideas have to do with machines that can. Like calculating machines. Right. So there were, like, mechanical calculating machines before there were electronic computers. There was something called abacus. The abacus was a form of this. There was also something called the. You know, textiles used to be weaved by hand, and then at some point, you built a machine, a loom, to do it. And then the Jacard loom, actually, you could program it.

[02:09:11.690] - Speaker 1
I've seen them.

[02:09:12.420] - Speaker 2
Yeah. So you have literally punch cards, and then you could do. And then patterns. And so they're running basically a very rudimentary computer program in order to basically do patterns. And it's a completely mechanical process.

[02:09:21.790] - Speaker 1
Player piano.

[02:09:22.510] - Speaker 2
Player piano would be another good example. Yeah, exactly. Right. It's not like Jakarta. Loom player piano are not what we call Turing machines, which is like, there's no concept of a loop. Like, you can't run any program on it, but you can run the program that generates beautiful textiles or beautiful music. Right. And those were both big advances anyway, so there were a lot of these ideas in those days, which people are thinking. There was this guy, Charles Babbage, and this woman, Ada Loveless, who had a design for basically an electronic computer in the 1860s that they were never able to build, called the difference engine, which is like. And you read the stuff. So Charles Babbage designed the computer called the difference engine that he fully designed is a great name, and it would have been a great thing to build. There's this genre now called steampunk. If you think about, like, the tv show or the movie Wild Wild west, there's an alternate reality genre called steampunk, where all this stuff actually started to work in the 18 hundreds instead of waiting longer. And so there's an alternate version of the universe where the difference is that what steampunk is?

[02:10:12.700] - Speaker 2
That's what steampunk is. Oh, cool. It's like living in the future, but it's a lost future where you had flying cars and mechanical.

[02:10:19.940] - Speaker 1
But everything's retro.

[02:10:20.980] - Speaker 2
And everything's retro. Everything's retro with all of. Everything's built out of what they would have had in the 1860s.

[02:10:25.440] - Speaker 1
I see.

[02:10:25.820] - Speaker 2
So everything's out of, like, wood and chrome and steel.

[02:10:28.120] - Speaker 1
Cool idea.

[02:10:28.830] - Speaker 2
Glass. There's no plastic. Right. Everything's out of the old materials. Yeah. So some of that stuff is really good. Anyway, these are ideas. And if you read the letters, Charles Babbage and Ada Loveless would send these letters back and forth. And Ada Loveless was basically the first programmer, and she was this young woman in literally 1860, it actually had a tragic life story. She died very young, but she was, like, writing software for the difference engine in, like, 1860. And they never built the difference engine, which means she never saw the software run, but they saw it, the ideas existed. And so anyway, so by the 1930s, there was this big debate that was already playing out, and this is even before the invention of the computer. And the big debate was, do we model the computer after a calculating machine? Right? So do we model it after the Jacard loom, the cash register, the player piano? Or do we model it after the human brain? And they knew just enough about neurology and the function of the human brain, and they knew the human brain was obviously capable of doing things that a calculating machine couldn't do.

[02:11:26.670] - Speaker 2
In particular, they knew the human brain was really good at patterns, right? So the human brain is really good at image recognition, really good at language. Here's a feature of the human brain. You can take a piece of text, you can take out all the vowels, right? So you take a paragraph of text the person hasn't seen before, you remove all the vowels, and you just leave the consonants. The human brain, you can still read that because your brain knows the patterns of words and letters and is able to fill that in. A calculating machine based computer can't do that. The human brain can't do that. So there's some difference. It's like sometimes the term fuzzy is used. So the human brain is fuzzy. And the problem with the human brain, by the way, is that it's fuzzy. And so will I remember tomorrow whether you were wearing that color shirt or some other color shirt, like, who knows? But you and I will have been able to have this conversation in a way that a calculating machine, you never would have. And so there's a fundamental difference, right, basically in there. And so these people in the 1930s knew that there was this difference.

[02:12:16.560] - Speaker 2
And so they said, should we model these things after a calculating machine in which they are hyper literal? You say almost autistic, right? Which is like, they're just like savant like machines, where they're really good at running large numbers of mathematical calculations very fast, and then we'll give people ability to write programs based on that. But they're never going to be good at patterns, they're never going to be good at language. They're never going to know what anything means. They're always going to be hard to talk to. You're never going to be able to use natural language interface. They're never going to be able to know the difference between the difference between a cat and a cinnamon roll in a photo, they're just not going to be good at that. So they'll be, like, hyper literal in that way. It's super fast, but hyper literal, and then humans will just still be completely different. Or should we try to build computers that are modeled after the human brain? And so it actually turns out the first paper on the concept of the neural network, which is the architecture of Chad GPT, was actually written in 1943.

[02:13:07.620] - Speaker 1
Wow.

[02:13:08.110] - Speaker 2
And the AI systems we use today are still based on the ideas in that paper, which is 80 years ago. Right. So they knew enough about neuron structures and synapses in the brain that they knew they was different, but they knew. And by the way, look, the field of AI started in 1943 like that. Actually fired the starting gun. And actually, people have worked for the last 80 years trying to get neural networks to work, and they finally just started to work. But my point is, they knew from the very beginning there were these two totally different ways of making computers, and they knew what the trade offs were. But it just turned out that historically, they were able to make the one kind of computer for the last 80 years, and that created the computer as we know it today. And then it turns out there's this completely other way to make a computer. And that's based on the. It's inspired by, it's not the same as the brain, but it's inspired by the structure of the brain. And as a consequence, it's a new kind of computer. And a way to think about it is it's a computer that's actually, an AI computer is actually very bad at all the hyperlittral stuff.

[02:13:55.970] - Speaker 2
Right. And so, for example, Chat GPT has this thing called it hallucinates. And so if you ask it a question and it knows the answer, it gives you the answer. If it doesn't know the answer, it just makes one up.

[02:14:05.440] - Speaker 1
So it's more creative and less accurate.

[02:14:08.040] - Speaker 2
Exactly. Somebody said, one of the guys who studies this says AI is not like a computer. It's like a pretty good person. It's not like the best person, but it's like a pretty good person. And what do we know about pretty good people? They're right a lot of the time, but a lot of the time they're not. And can you always tell the difference? Not necessarily. Do they sound as confident when they're wrong as when they're right? Yeah. Do they know? No, they don't.

[02:14:29.350] - Speaker 1
If you ask, it sounds like a real issue. If we've spent 80 years establishing the fact that what you're getting back from a computer is more like the results from a calculator. But now we're getting these fuzzy results that are more like mediocre human results, even though we've had 80 years of what we think of as accurate. That could create confusion.

[02:14:56.040] - Speaker 2
Yes. So there was a court case about three months ago where a lawyer had Chet GPT write a legal argument to be presented to a judge in a court, and it did it, and it hallucinated several court cases, precedents that don't exist. And the judge caught it, just made them up. Made them up. And they sound great, by the way. They sound exactly like court cases. The whole thing hangs together logically. It's just literally not true. It's based on cases that didn't happen. And it turns out if you submit false, made up court cases in court, you get disbarred as a lawyer. Like you're done being a lawyer. And so the judge basically came very close to disbarring the lawyer on the spot. And the lawyer is basically, the judge is like, did you use Chat GPT to do this? And the lawyer basically fessed up, and the judge basically said, if you ever do this again, I'm going to disbar you and destroy your career. It's exactly for that reason. But however, hallucination, creativity. Yeah.

[02:15:43.870] - Speaker 1
Be a great scene in a movie, for example.

[02:15:45.870] - Speaker 2
Exactly.

[02:15:46.420] - Speaker 1
Work fine in a movie.

[02:15:47.450] - Speaker 2
Well, so. And it actually turns out so there are companies now building AI for lawyers. So we did a bunch of work we haven't invested yet, but we've done a bunch of work in this space. Because one of the things that AI can do is it can write legal briefs, and if it doesn't hallucinate, they're actually really good legal briefs. And so we've been talking to professional lawyers about this, and what the professional lawyers will tell you, actually, is you actually don't just want accuracy when you're thinking about writing legal briefs. You actually do want creativity, because there are different ways to make legal arguments. And maybe the way that you've thought of on your own is not the best way to do it. And maybe if you had a copilot think of, you're writing a legal brief, you're a lawyer, you're writing a legal brief, you have a copilot, right? And that copilot is just giving you ideas, right? And some of the ideas are going to be great ideas, some of the ideas are going to be terrible ideas, but they're all new ideas, ideas where you don't have to sit and come up with them on your own, right?

[02:16:32.640] - Speaker 2
And so what the lawyers are saying basically is, like, in that case, you want some hallucinating, right? You don't want make up a court case that didn't happen, but you want, oh, here's a different way to make the same argument. Or you might also view it as like, if you're writing a closing argument, to be presented to a jury like that. As you know, there's like a storytelling exercise. And so you might want actually some brainstorming. You don't want the thing to do it for you because you're the guy who has to stand up there and actually present it, and you have to really be willing to stand behind it. But it might be helpful to have a writing partner that can actually help you do that. And so there's this sort of double edged. The fact that it hallucinates is both a big problem, but it's also magical because we've never had computers that make things up before. That's a brand new thing. If you had told me three years ago, we're going to have computers that make up court, there's never been a way to do that. It's the same thing. Now you're seeing it.

[02:17:21.060] - Speaker 2
The way to see this really clearly, of course, is now visual design, visual art coming out of, like mid journey or dolly or these things where it will make up all of these crazy art things. And look, half the time it will make up like it will. And there's this famous thing. They've figured it out now, but for a long time, the way that you could tell that computer art was being made by an algorithm was it would give everybody extra fingers. It just turned out that the training data it was trained on is just like. It just turns out like human body is relatively straightforward, except that there are these detailed finger appendages, and if you are looking at a billion photos or pictures of people, they have fingers in all kinds of different positions. And so the early versions of the AI art basically just didn't know how to do fingers accurately. They've fixed that now where it no longer does that. But by the way, if you want it to, it still will. Right? And so if you tell it, render me a scene where everybody has seven fingers, it will happily do it for you.

[02:18:09.110] - Speaker 2
And computers never used to be able to do that. Or if you just want to tell it to use its imagination, one of the things you can do that's really fun with these things is you can do it. You can say, like, use your imagination, or you can say. Another thing you can do is you can say. So there's this thing called prompt engineering. So it's, how do you write out the prompt that tells the AI what to do? Right, which is true for both a text AI and for an image AI. Do the prompt. And it turns out there was this research thing done by Google a few months back about, what's the optimal prompt that optimizes the chance that there won't be hallucinations, that it's going to be the most likely to be what's called factually grounded. And it turned out the optimal prompt starts with take a deep breath.

[02:18:43.980] - Speaker 1
Really?

[02:18:44.510] - Speaker 2
Yeah. Gives you the best results. Right. And this gets to the amazingness of what's happening. This is why we're also transfixed by this. It doesn't have lungs.

[02:18:52.760] - Speaker 1
No, it doesn't breathe.

[02:18:54.550] - Speaker 2
It doesn't breathe.

[02:18:55.350] - Speaker 1
Right.

[02:18:55.920] - Speaker 2
So it's not that. But also, look, if I tell you. If I ask you a complicated question, I say, take a deep breath. I'm also not telling you to take a deep breath. What I'm saying is pause and think, right? What that's code for is pause and think. So it's like, okay, so what you're telling the computer is pause and think. Okay, that makes more sense, because, okay, pause and think. But then it's like, wait a minute. Why do I have to tell a computer to pause and think? Like, why would that matter? So it turns out why that matters is because the way these systems are built is they're trained on these giant billions and billions and billions of files of text and images that other people have created over time, throughout all of human history. Like, all that stuff's been fit in there. And it just turns out that in the total material of all text that everybody's ever written on any topic, anytime anybody ever says, take a deep breath, pause and think, it means that they're more careful in how they do their work, right. And they actually act differently in how they do their work.

[02:19:44.500] - Speaker 2
They go more slowly. They go step by step. They double check all their assumptions. And so that's, like, encoded deeply in the sort of total collective unconsciousness of how we express describing human thought, such that when you tell the machine to do that, it kicks it into a very similar mode as that.

[02:19:58.970] - Speaker 1
Very interesting.

[02:20:00.580] - Speaker 2
And everything I just described, I would have been, like, committed to an institution five years ago if I had said that this is what we were going to be doing. And now all of a sudden this is actually happening. And so that's the. Yeah. So the breakthrough is computer, a completely different kind of computer that is able to basically synthesize and deal with patterns in human and human related expression, language and photos and images and videos and all these things that humans deal with eyes and ears, like all this stuff, in a fundamentally better way that is based on and analogous to how human brains operate, but also very different. It's like this brand new frontier.

[02:20:36.540] - Speaker 1
Tell me the OpenAI story. It started as a nonprofit, not for profit.

[02:20:41.370] - Speaker 2
It is, and it continues to be a nonprofit.

[02:20:43.060] - Speaker 1
Tell me that story. Because there was a story about it becoming a for profit.

[02:20:47.200] - Speaker 2
Yeah. So it's a nonprofit that owns a for profit. So it's a non profit parent company with a for profit subsidiary.

[02:20:54.560] - Speaker 1
Is that a common.

[02:20:55.540] - Speaker 2
No, that is not common.

[02:20:57.110] - Speaker 1
Has it ever happened before?

[02:20:58.120] - Speaker 2
It has happened before, yes.

[02:20:59.400] - Speaker 1
What was the.

[02:21:00.230] - Speaker 2
I'll give you an example. The Guardian newspaper in the UK is owned by a trust, Johnson Johnson, the consumer products company, I believe, is owned by a nonprofit. I think the Lego company, I think, is owned by a nonprofit. I'd have to double check all these, but I think these are all examples. There have been a bunch of examples like this. So it has happened before. It is allowed. Having said that, there are very stringent tax laws that apply lie to this, because you're not allowed. Nonprofits are not allowed to pay, like, high salaries. You're not allowed to do what's called self dealing. You're not allowed to extract money out the other end. Because the whole point of being a nonprofit is you don't have to pay taxes. And so the IRS supervises nonprofits that own businesses, actually, quite strictly. And there have been people who go to jail when they cross those lines. So you have to be careful in how you do this. But, yeah, so basically, OpenAI started out as a nonprofit research institute. It actually didn't even start with the for profit sub. It just started as a nonprofit. It actually started, was started by Elon Musk and a group of people kind of that Elon brought together, including Sam Holtman, who's now the CEO.

[02:21:56.040] - Speaker 1
Is he the CEO?

[02:21:57.230] - Speaker 2
He is sitting here today.

[02:21:58.120] - Speaker 1
He is once again today. He is the CEO today he is.

[02:21:59.750] - Speaker 2
Once again the CEO.

[02:22:00.370] - Speaker 1
So he was fired and rehired.

[02:22:01.490] - Speaker 2
He was fired and rehired within five days.

[02:22:03.320] - Speaker 1
That's interesting.

[02:22:04.090] - Speaker 2
And they had two other ceos in the meantime.

[02:22:05.840] - Speaker 1
Maybe you'll tell me that story. We'll get there in the history.

[02:22:09.350] - Speaker 2
Sure. Elon has talked about this now in public. So basically what happened was Google obviously makes all their money in the search engine, but the guys who started Google, Larry Page and Sergey Brin, came out of the AI group at Stanford. And so they got trained up in all this AI stuff when it wasn't even working. Right, pre Google, they were PhD students at Stanford studying AI before they built Google. And so their kind of orientation in the world is basically AI. And they basically always viewed Google as, like, a simple form of AI, but they always aspired. Like, if you read their interviews, they always said Google shouldn't have the ten blue links. It should just give you the answer. And so they started doing AI research early on at that company when it first got started, and they did it for many years. Yeah. So they basically launched an internal research group called Google Brain. They launched that, I don't know, 15 years ago or something. And the goal, basically was to develop AI. And they actually developed the actual breakthrough, the specific version of the neural network that makes all these systems work.

[02:23:07.700] - Speaker 2
Now it's called the Transformer. And that was actually invented by a guy, two guys I know, wonderful guys, in 2017. And so that was, like, the key theoretical breakthrough that finally made all this stuff work.

[02:23:18.260] - Speaker 1
Was it owned by Google?

[02:23:19.800] - Speaker 2
Yeah. Well, no, this was considered research, not development. And so the way that it was, like, an internal scientific unit at a company, and so they actually published it as a paper. I see. There's a long history of this, where actually a lot of the great breakthroughs over time have actually come out of, like, industrial research labs like this. And then the company that develops it publishes it, and then they don't realize until later that they should have kept it secret. But also the reason that they were able to hire all these great researchers out of all these universities is they promised them that they could publish their work. Right. And so it's sort of part of the deal with these guys was that they would get to publish. So they had this key breakthrough in 2017, but it sort of became clear in the 2010s that there was finally progress being made and that some of these systems were going to start to work. And Elon had some conversation with Larry Page, who was running Google at the time. And Larry said to Elon, this AI thing is really going to work, and we're going to end up with ais that are much smarter and more powerful than people.

[02:24:11.210] - Speaker 2
And Elon said, well, aren't you worried that they're going to have their own goals and they're going to take over and they're not going to want us around anymore. And Larry's response was, you're being speciesist, you're being racist, but towards your species. And if they're a better form of life, then they should take over and we should all die and humanity should go away. Now, knowing LARRY, I think there's at least a 50% chance he was joking. But EloN cOuldn't tell and took him SEriOUSLY. And SO Elon had a visceral reaction and was LIKE, oh, my God. The big RIsK here is not just developing AI. The big risk here is Google develops AI, and Larry Page is in control of it, and he does horrible, horrible things. And so he started, he's like, so he called all these people who he knew and he said, we need to start the competitive effort to that today. And we need to call it, it needs to be, as opposed to GooGLE's closed AI, it needs to be open AI.

[02:25:00.990] - Speaker 1
And this was to protect the world.

[02:25:02.500] - Speaker 2
It's to protect the world, in ELON's view, is to protect the world. So what Elon says is we need to go hire all the best researchers we can.

[02:25:07.980] - Speaker 1
It seems to be. That's what he's always done. It's like Tesla was, cars need to be electric, SpaceX was, if anything happens to the Earth, we could live on Mars. He's always motivated by saving the planet.

[02:25:21.550] - Speaker 2
Yeah, that's right. And humanity. Right, exactly. And save humanity. Yeah, no, I think that's true. Look, I mean, Tesla has been a climate story the whole time and still is, for sure.

[02:25:29.340] - Speaker 1
From the beginning, it was.

[02:25:30.240] - Speaker 2
Yes, that's right. In fact, Tesla, as you know, Tesla isn't just cars, they're also batteries. Right?

[02:25:34.560] - Speaker 1
And he also, I remember from the beginning of the first Tesla announcement was, and I'm hoping every car company steals our technology.

[02:25:42.080] - Speaker 2
That's right, that's right. No patents. He open sources everything. Exactly.

[02:25:45.360] - Speaker 1
For everyone. It was always for everyone.

[02:25:47.550] - Speaker 2
That's right. That's exactly right. Yeah, that's right. And so that's what he did here. And then what he did, basically, was he said, look, if you're an AI researcher and you're interested in money, then you can go to work at Google and they can pay you a lot of money. But if you care about the mission of having it be open, then come and work with me. And he called it OpenAI, and he made it a nonprofit, not a know. And then he said, basically, he said, everything we do at OpenAI is going to be open sourced in the same way. Right? So he said, basically, if you come here, your work is all going to get published. Everything's going to be open. He even said early on, he said the mission of OpenAI is to make sure that AI is happens and is safe and is universally available to all of humanity. And he said it would actually be fine if somebody else does that and makes it available, in which case OpenAI will just shut down and our mission will be complete, I think. So it was set up as nonprofit. It was registered as a nonprofit.

[02:26:31.690] - Speaker 2
He donated it, what is reported to be something like $50 million to get it off the ground. And then a group of people, including Ilana, Sam Altman and others, then brought in a lot of these people, these names now, Greg Brockman and Ilya Sutzker and a bunch of these, like, really smart guys, and they formed this thing and they got underway. And then basically, it's a long story, long, detailed story. But in the beginning, this is like 2014 or 2015. They didn't have the transformer yet, so they didn't know how to make jet GPT work. They were primarily working on trying to have ais that can play video games in those days as sort of a proxy for being able to make decisions and so forth. But it didn't go that well. And so it was sort of start and stop, and some things worked and some things didn't. And so it was kind of a little bit, kind of iffy along the way as to whether it would work. And then basically, at some point, stuff really started to work. Like, the things started to actually perform really well. And then, in particular, there was this breakthrough.

[02:27:22.340] - Speaker 2
There was a large language model breakthrough. And the way I've heard the story is there was one guy there whose name is Alec Radford, who had this idea for these language models, and the rest of the organization thought he was nuts and didn't want him to do it. And he's like, no, I think we might actually be able to make this thing work. And this transformer thing came out, and then they started to get. Then they did GPT one, which was the first version of the text, LM. And then they were like. And then they did GPT-2 and they were like, okay, this is really going to be a thing. And then basically, what happened around that time is this guy, Sam Altman, basically came. He had been sort of an original founder, but he'd kind of disengaged. And then he kind of came back in and sort of, he took control of it. Elon, there's controversy over this, but Elon became less involved. Tamp took control of it. And then Sam did this very important thing, which is he created a for profit subsidiary under the nonprofit.

[02:28:05.190] - Speaker 1
And why did he do that?

[02:28:06.370] - Speaker 2
So what he said, and I'm sure this is true, what he said was to make these large language models work, we need a lot of computer capacity and we need a lot of data, and we're going to need billions of dollars. Basically, he said, I know how to raise $100 million from nonprofits. I don't know how to raise $10 billion from nonprofits. It's just hard to do that, not many of those running around. So he said, we're going to create a for profits subsidiary so that we can basically sell shares in that for profit subsidiary and generate revenue. And generate profits. And then that's what will let us raise the money, because if we can't raise the money, we won't be able to keep going on this research, which means, by the way, ultimately, it will all be done by an actual for profit company, right, like Google or Microsoft. And then OpenAI won't win. And so he turned what had been a pure nonprofit into a nonprofit that owns a for profit. The employees of the nonprofit became employees of the for profit. Salaries went up a lot. The amount of money that they raised went up a lot.

[02:29:01.120] - Speaker 2
Their ability to invest went up a lot.

[02:29:03.440] - Speaker 1
What was Elon's participation for the original 50 million?

[02:29:07.120] - Speaker 2
So Elon has said publicly that he got nothing for it. What he says is it was a philanthropic donation. Under tax laws, you can't just turn a nonprofit into a for profit.

[02:29:16.490] - Speaker 1
Right.

[02:29:16.870] - Speaker 2
Because it's a violation of tax laws. And so I think, legally, they probably couldn't give him anything. But anyway, he says he got nothing for it. And he has said in public, basically, he's like, wow, that seems like a neat trick. Why doesn't everybody do it? And so he has suggested over the years that there was something wrong with how they did this. And who knows? We'll see. But Sam made that change. And by the way, that worked, right? They were able to all of a sudden start paying competitive salaries to Google for engineers. They were able to buy all the computer power they needed. They were able to buy. They have lots of money going into making training data. And so that part of it worked, and that's what resulted in Chat GPT. That's why Chat GPT exists, and that's why Dolly exists. He did another thing along the way, which was he turned it basically into closed AI. So he turned it into a for profit, and he canceled the part where it publishes everything. And basically, as of four years ago or five years ago or so, they stopped publishing their research.

[02:30:06.280] - Speaker 2
And he did that under the theory that it's too dangerous to distribute, it's too powerful, too dangerous, and other people can't have it. But there's some irony in that, which is the whole reason OpenAI exists is because that was what they were. Elan and Sam were afraid that Google was going to anyway. So it's been this rather dramatic kind of shift.

[02:30:24.340] - Speaker 1
Why was Sam removed and then replaced?

[02:30:27.350] - Speaker 2
So we don't fully know yet. They're a relatively opaque organization. A bunch of stuff has been reported. You never quite know whether what's reported is true or not. There are going to be many investigations in the months and years ahead from government, and there's going to be litigated lawsuits, and there's going to be a lot of. There's going to be, by the way, there's going to be multiple books written about this already underway. There's going to be a Netflix series, I'm sure. Right. And so we will learn a lot in the years ahead about what just happened.

[02:30:51.380] - Speaker 1
Is Microsoft somehow involved?

[02:30:53.130] - Speaker 2
Microsoft is very involved.

[02:30:54.430] - Speaker 1
How is Microsoft?

[02:30:55.280] - Speaker 2
Microsoft is their major investor in the for profit. In the for profit. And so they have raised $13 billion from Microsoft into the for profit. And they have this very elaborate, complicated structure. So they now have this structure. They're still a nonprofit at the parent company level, but they have this for profit subsidiary. And then they have this very complicated system for how they account for investor money versus donation money and how things get paid out. They have this new structure they've invested called cap return. So if you invest money in the for profit, you get paid out up to like a ten x return on your investment. And then after that, the profits all go back to the nonprofit. There's what's called a waterfall. So different investors investing at different times get precedents for how the money comes out. And then Microsoft's just the vast majority of the money. So they have tremendous control. They have kind of the most outside control of anybody. But it's a nonprofit. They can't operate as just a business. And so they've got this additional nonprofit overlay. All investors who invested in this thing over the years signed paperwork that very specifically said, you are investing in a for profit sub of a nonprofit.

[02:31:52.270] - Speaker 2
It would be best if you thought of this as a donation, not a financial investment. And then they say, but that's probably okay, because who knows whether there will even be money once we have AI anyway. That's like literally in the document. Right. So everybody's invested, who's invested in this is kind of known that that's the deal. But then they have this additional thing that they are very kind of vocal about and public about, which is this idea of AI safety. And this idea, the original concern of is AI going to basically wake up and destroy everything, take over and wipe out humanity or just cause damage in one of a thousand other ways. And so they also have this thing built into their structure which basically says if they conclude AI is too dangerous, they'll basically just shut the whole thing down. Right.

[02:32:31.940] - Speaker 1
Where's the line of dangerous?

[02:32:33.800] - Speaker 2
That is a very good question. That is a question that every expert in the field has a different opinion on. There is heated controversy over it. I am on the side of what's known as the accelerationists. I think there basically either is not a line, or if there is, it's so far out in the distance, it's not worth thinking about. And we're nowhere close to it. And we shouldn't worry about this. There are a lot of people that are called safetyists or that sometimes get referred to as the doomers who are convinced that the line is already like, we're almost there and we might trip it at any moment. There was a news story yesterday that I don't know if it's true, but it suggests that there were a group of people inside OpenAI that basically blew the whistle and hit the red button and said it just got too dangerous and we need to kill it right now. And so there's reports that this played a major role in Sam getting know there's irony to that because in the wake of Sam getting fired, they all decided that they were going to go work for Microsoft, which is just a big for profit company that presumably is not going to care as much about safety.

[02:33:25.610] - Speaker 2
So if this is such a concern that they're going to fire Sam over it and shut it down, why are they all going to go to Microsoft, which is probably even more dangerous? And then Ilya, the chief scientist, actually flipped. He reversed himself. He actually fired Sam. He was on the board, and he's the guy who fires Sam. And then 24 hours later, he reversed and actually said that he actually wants Sam back. And so there's this debate over why he changed his mind. And was it because he decided Microsoft was more dangerous than Sam? So this has been the drama. So this has been the thing that's been consuming the industry for the last week. It's been this spectacular, amazing, kind of just like meld down, resurrection kind of thing that's happened. Every question that you just asked, the question you just asked just remains a very open question, which is like, okay, again, based purely on the reporting, have they discovered. So the reporting, basically, is that they've discovered, for the first time, a self improvement loop. So the claim is that they've discovered a loop that basically where the AI can improve itself and the AI safety.

[02:34:19.460] - Speaker 2
Doomer, people. Safety is the polite word. Doomer is the preservative. Those people basically say, if you have an AI that can improve itself, then it will inevitably become all powerful because it will improve itself and then improve itself and then improve itself, compounding all the way up. And they call this the takeoff scenario. And the takeoff scenario, basically is you get into an improvement loop, and within conceivably 12 hours, it's become super God. Right? And it takes complete control of nuclear weapons. And you have Skynet and the whole thing.

[02:34:46.720] - Speaker 1
What's really interesting about it is because it's built on human models and the way humans work. If a group of humans had ultimate power and could press a button that would turn off half of the world, that would likely happen.

[02:35:06.710] - Speaker 2
Well, most human stories, the good guys win. Most human stories, when the bad guys win, we call it a tragedy and we feel bad about it.

[02:35:18.040] - Speaker 1
I mean, the good guys wrote all the history books. Hard to know.

[02:35:20.840] - Speaker 2
Guys wrote all the history books.

[02:35:21.880] - Speaker 1
Impossible to know who the good guys are.

[02:35:24.370] - Speaker 2
We have 8 billion people on the planet today, far more than ever before. The world has never ended. Despite the threats of many apocalypses over time. Oppenheimer, the nuclear weapons. The whole point of Oppenheimer is nuclear weapons are going to destroy everything. Nuclear weapons didn't destroy everything. Nuclear weapons actually probably prevented world War three. Right? So it turns out developing the doomsday device thus far. Thus far, yes, thus far. Exactly. 100% thus far. Right. Exactly. Well, but look, if you had just been through world war, we've forgotten how bad World War II was. If you had just been through World War II, the expectation of all the military planners in the 1950s was world war three was right around the corner, and it was going to be a land war in Europe against the Soviets, and it was going to kill 200 million people. And look, we still have troops in Germany for that reason, like, 80 years later, because we thought the Russians were going to invade. Right. And that looks like what was going to happen. I think most historians are like, yeah, that was highly likely to happen. And basically it was only the threat of global destruction in World War II.

[02:36:17.490] - Speaker 1
We were on the same side as Russia.

[02:36:19.060] - Speaker 2
Exactly. We were. And then that flipped hard in the years that followed. Very hard. Well, look, there's all kinds of questions around this. I don't even think we have a good history of what happened in the 20th century. Look, the Nazis were very, very bad. The communists killed even more people. Right? Like, look, we turned over half of Europe to the Soviets and they turned it in. They brought down the iron curtain and they killed many millions of people and they imposed into a horrible dictatorship. And like, surveillance society and East Germany is just a fucking nightmare, right, of what they did to those people. And we did that all to protect them from. Yes. Good news is we protect from the Nazis. Bad news is we turn them over to the communists. There's like some big. The idea that there was anything morally pure or clear about World War II, I think, is just like completely fake. Right. It's just only because we have this mythology around it. I don't know, it seems like it ended very badly. And I'm not saying, I'm far from saying that we shouldn't have done it, but have you really achieved a great moral victory when the guy who killed more people is a guy who wins?

[02:37:17.600] - Speaker 2
Right. How's that going? Right. We spent the next 50 years like literally terrified that there was going to be some combination of either world war three or nuclear Armageddon. And then the plot twist is the threat of nuclear Armageddon probably prevented World War II. Right, right, exactly. And so, like, okay, that's in our history. That's real. Yeah. So look, AI is going to get trained up on that right now, by the way. The other thing is, it's very easy to anthropomorphize AI. It's very easy to impute.

[02:37:41.890] - Speaker 1
Well, all it knows is what humans.

[02:37:44.840] - Speaker 2
That's true, but also it doesn't know things the way we know things. So it's not a brain. It's modeled after the brain, but it's not a brain. I'll give you a bunch of differences. So it hasn't been evolved. So you and I are the result of 4 billion years of evolution where it's been a pitch battle for survival across that overwhelming period of time. Right. And why are human beings so crazily violent and always killing each other? It's because that was 4 billion years of evolution said, you're fucking trying to kill the other guy because if not, he's going to kill you. In EU, every living organism is the result of 4 billion years of biological pressure inclined towards violence. Ais are not like that at all. They're not evolved. They're programmed. None of them are programmed like that way. And so they don't work like that at all. Look, whatever there is to a human spirit or soul or personality or sense of consciousness or identity, the machine doesn't have that at all. Chad? GPD is not answering.

[02:38:35.710] - Speaker 1
But maybe that's the thing that saves us the.

[02:38:39.500] - Speaker 2
Exactly.

[02:38:41.020] - Speaker 1
If it's got all of human thought without the soul. Seems dangerous.

[02:38:47.360] - Speaker 2
I don't know. Well, so here's the other thing, though. You can also test this. One of the interesting things about. So the fictional portrayals of AI are all basically. I think they're actually inspired by fascist nazi esthetics and ideology. The assumption is they're going to militarize, right? Terminator is like the case study of this. It's like, basically, the Skynet is basically machine version of nazis, right? It's even in the iconography and the chrome and the steel and the machinery and the evil pyrial malevolence and the red eyes and the concentration camps in the movies and the death machines and all this stuff. And in the matrix, it's like they're literally harvesting human biological essence for energy. So it's all this fascist, top down, death machine kind of thing. But when you actually use these systems, that's not how they act at all. In fact, generally they come across when I use them is they're very curious, they're very open minded. And by the way, they're happy to engage in moral arguments. And so you can ask them lots of questions about what is the proper way to live a life, what is the proper way to organize a society?

[02:39:51.260] - Speaker 2
And you might agree or disagree with what they tell you, but it's pretty representative of what most people have said over time. And it's kind of like they'll happily tell you that, generally speaking, people should be nice to each other, and generally speaking, people should respect each other's differences. It's not Terminator. It's something else. Right. And what is that something else, to your point? It's the composite of all of human experience. But also, this is very important. There's no it in the way that we think about it. There's no little person in there.

[02:40:22.280] - Speaker 1
I understand.

[02:40:23.080] - Speaker 2
Right. It's not.

[02:40:24.540] - Speaker 1
There's no point of view.

[02:40:25.810] - Speaker 2
Another way of thinking about it is what it's doing is it's generating Netflix scripts. It's generating Netflix scripts. Stories.

[02:40:31.570] - Speaker 1
It's generating stories on the storytelling machine.

[02:40:33.740] - Speaker 2
All it wants to do is tell you a story that you're going to.

[02:40:35.870] - Speaker 1
Like, tell me the different categories of software between the Internet and my eyes. Everything. What are all of those things that happen? What are all the different processes that happen software wise, like using Netscape as an example of one of the pieces. But it's not all the pieces. So what does, what, what are all the pieces you need?

[02:41:00.500] - Speaker 2
So somewhere there's a piece of, let's say there's a piece of content. You're looking at a web page. That content is stored in a storage system somewhere. It's stored in a hard drive somewhere that is managed by a computer called a server. That could be literally a computer sitting in a closet somewhere, or it could be in a cloud, which is basically just a giant collection of computers kind of run as a big grid. And then there's the hardware, server computer and storage. And then there's what's called server software. So there's the software that gets the request for the content and then responds with the request.

[02:41:33.680] - Speaker 1
That software would be built into that system, though it's not an added on piece.

[02:41:38.330] - Speaker 2
Yeah, there's server software. It's called a web server piece of software which would run on a server computer. Usually the terminology we use is client server. So client is like what the user uses and the server is like what's running in the background somewhere. And so when I say server, that can mean both the hardware itself of a computer in a closet somewhere, or it can mean a piece of software running on that computer that does server like functions, that tells it how to be a server basically. So there's server software running up in.

[02:42:06.410] - Speaker 1
The cloud and that's always connected to the server. So it wouldn't be a general one that would talk to other servers, it would only talk to that server, the software.

[02:42:15.380] - Speaker 2
So the simplest case is just a single computer, a single server computer with a single piece of server software on it. Now in practice, most of what you have today is much more complicated than that. These systems have evolved to become a lot more powerful. And so probably what's actually happening, like if you're looking at a web page today is probably you're accessing the server is a cloud of like a million computers and you're just hitting randomly one of those computers versus another one. And there's a network switch that's balancing across the million other people that are trying to access the same content at the same time. So it's become a very elaborate plate spinning exercise on the back end. And there's these giant businesses like Amazon Web services that manage all that, but it's still the same. What you experience is still the same thing as far as you're concerned. It's just a server. It's just giving you content. There's probably two really critical other things that happen back there. One is there's a lot of work that goes into making this fast. And so there's this process called caching. And so there's probably another server that is actually closer to you that's like at the telecom company that use your wireless provider that has a copy of that content already on it so that it doesn't have to actually go all the way up.

[02:43:21.480] - Speaker 2
And so there's what's called caching systems, performance systems, and then there's all these security systems. The servers can get attacked. Right. There's lots of hackers that want to break in or disable these systems. And so these days, they have all these defense mechanisms to be able to fend off cyberattacks.

[02:43:35.080] - Speaker 1
What would a hacker want to get into it for?

[02:43:37.550] - Speaker 2
So a couple of things. One is to get, a lot of it is to try to get the user data. So to try to get your name and password and credit card number, or theft. Theft. Or they might want to maliciously change the content, deface it, graffiti artist it digitally. Or they might just want to destroy. They might want to actually take that server offline. They might not want it to exist anymore. And what they do when they don't want it to exist anymore is the bad guys will do what's called a denial of service attack, which is a DOS or DOS attack. And basically that means that the bad guys basically set up a large number of hostile computers to just barrage the server with too many requests and cause it to basically melt down. And so there's all these elaborate systems, by the way, the chinese government does this. So the chinese government has the great.

[02:44:22.030] - Speaker 1
We know that.

[02:44:22.710] - Speaker 2
We know that because it's now been well documented. So one of our companies was the first company that experienced this. So the Chinese have what's called the great firewall, which prevents their citizens from looking outside. The great firewall consists of millions of computers that are being used for censorship and filtering. They have a capability to turn the great firewall into something we call the great cannon. And so they can turn it into an outward bound attack.

[02:44:45.380] - Speaker 1
Wow.

[02:44:45.810] - Speaker 2
And it's so big and so powerful that it can overwhelm any sort of small Internet company. And even for the big Internet companies, this can be hard to fight. Off. And so there's actually these pitched, there's almost these pitched digital wars that take place where the Chinese or other.

[02:44:59.700] - Speaker 1
Is this happening all the time or. It's on occasion.

[02:45:02.010] - Speaker 2
Well, the Chinese aren't always doing it, but there's always denial of service attacks. Somebody's always trying to do it. So it's actually not that expensive to run a denial of service attack. You might even just do it for commercial competition reason it's Christmas. You're competing with somebody. If you're nefarious, what you would do is you would basically mount a denial of service attack against your competitors website so that they couldn't sell anything. Right. And I'm sure that's happened, too. Right. And then there are these things called botnets. And so one of the things that computer viruses do is if your computer gets a virus, it gets basically recruited into a botnet, and your computer ends up getting used to do these attacks. Or by the way, your toaster your, like, there's this digital war that's kind of constantly taking place. North Korea does a lot of hacking. They do a lot of hacking for financial reasons. They fund a lot of their military through hacking for financial crimes. And then they hire third party hacker rings on the Internet to do it for then, by the way, there's also, like, mass propaganda efforts. And so a lot of nation states now have what they call covert influence teams.

[02:46:04.240] - Speaker 2
And then that form of the attack is to upload lots of fake content and to try to overwhelm the real content or whatever, create lots of fake accounts. These days, whenever you are doing that, your computer is kind of maneuvering very elegantly through this kind of digital firestorm that's happening all the time. And so you generally never notice it, but it is actually happening. But the amount of brain power in computer hardware that has been spent over the last 20 years trying to get these systems to be good at repelling all these attacks is actually quite staggering. It's like this whole parallel kind of cyber war that's taking place. And of course, this is just the very beginning. These wars are going to get much more intense in the years ahead. We haven't yet had a full, basically military war that's been accompanied by a cyber war. But what everybody's worried about is like, okay, if for somebody of Russia were to decide to invade Germany, for example, would the first thing they do is take down the german power grid? I don't know, maybe, right know, maybe hack into all the self driving cars and cause them to all drive off the road or crash into each other.

[02:47:06.720] - Speaker 2
Right. And so there's real world consequences more and more to all these things. So anyway, so that's what's happening on the outside. And then basically, you've got your wifi or whatever here or your cell connection, and then you've got your computer, and then your computer. Correspondingly, your iPhone or your Mac has many layers of software to basically deal with all that, download the content, render the content for you. That takes place in the web browser, usually, or the operating system somewhere and present it to you in a good way and then let you interact with it. And so that's what's called the client.

[02:47:36.830] - Speaker 1
All there is. Is the browser on your side or is there more than a browser?

[02:47:41.810] - Speaker 2
Yeah. Well, the browsers have gotten very complicated, right? So correspondingly, the browsers are also now very sophisticated. And so, for example, I'll give you an example. Your browser has all sorts of security countermeasures in it also itself. And so if you download a piece of content that's been compromised and has, like, a malicious worm or virus inside it, your browser and your operating system have ways of detecting that and preventing that from infecting your system. So it's got that. It's got all kinds of things in there for performance making everything fast. It's got things in there for dealing with video and music.

[02:48:10.320] - Speaker 1
On the simplest level, forgetting the war aspects of it, even though those are real world concerns, the actual connection is pretty simple. It's a server talking to a browser over the Internet.

[02:48:25.360] - Speaker 2
Yeah. And you can still do exactly that. You can still run it exactly that way. That still works in practice. Nobody does that anymore because it's all gotten much more sophisticated behind the scenes, but not in a way that you would ever notice if all of the other complicated stuff is doing its job right. You never notice that it even exists. And so you experience fundamentally the same thing you would have 20 years ago. Part of the magic has taken place. Like, there's a huge amount of plumbing that's been built that makes all this work, that it's just kind of many hundreds of thousands of very smart engineers have spent 20 years, and big, huge industries have been built trying to get this stuff to work, by the way. It's all going to get. Another thing is going to get more complicated. So AI is now going to get used for planning and executing cyberattacks, and AI is also going to get used for defending against them. Right. And so a browser three years from now will have an AI built into it that will be doing cyber defense for you. And again, you may never know that's even happening, but it will kind of doing that on your behalf.

[02:49:16.530] - Speaker 1
How much time do you spend on YouTube?

[02:49:18.560] - Speaker 2
Quite a bit. Quite a lot. Yeah, it's an amazing. For me, it's almost entirely long form. It's discussions, podcasts, even audiobooks. But it's just like the repository of information knowledge on YouTube is just incredibly staggering. And then actually a lot of music, I do a lot of music listening on YouTube now.

[02:49:35.390] - Speaker 1
Has it replaced other forms of visual media?

[02:49:39.850] - Speaker 2
Yeah, I think, yeah.

[02:49:41.520] - Speaker 1
Less television, less movies, more YouTube.

[02:49:43.730] - Speaker 2
Well, no, I don't watch, my eight year old watches YouTube in preference of television movies. I don't do that. If I'm watching television or movie, I want a very specific experience. It's usually with friends or at the end of the day, and I want to watch whatever is the best new movie or whatever. So I just don't have the mode of sitting and watching YouTube videos or TikTok videos the way that a lot of people do. And it's just frankly the lack of time. I'm sure it would be very fun. But for me it's basically, it's actually mostly, actually for YouTube is audio content mostly for me, it's an audio source. So I'm an audiobook podcast, spoken word, know, like 2 hours a know, driving around and running around and doing everything, getting ready in the morning. And so it's usually either I'm listening to a slash podcast or an audiobook. But YouTube has been taking a bigger and bigger share of that.

[02:50:27.340] - Speaker 1
What was the piece you wrote recently, the optimist, what was it called?

[02:50:31.920] - Speaker 2
The techno optimist manifesto.

[02:50:34.120] - Speaker 1
Techno optimist manifesto. Please explain it to me.

[02:50:37.090] - Speaker 2
Yes, it's both radical and not radical at all. This is my history. Obsession comes in. So it's very radical in that it says these things that have become very radical, which is technology is overwhelmingly net good, capitalism is overwhelmingly net good. And basically, the more technology and the more capitalism we get, the better things are going to get. And I describe sort of in detail why that's the case. I describe in detail what the arguments are against that and why I think that they're wrong. I also describe, by the way, the limits to that position, the things that I'm also not claiming. But it's basically, it's a call to arms for the kinds of people who build new products, build new technologies, build new companies. I describe right up front in the piece that basically, I think we have all been on the receiving end of a demoralization campaign for the last 15 years to basically convince us that all these things are bad and evil. And I think it's basically a demoralization campaign is being run by people who are very threatened by change and people who are very resentful and bitter, and we should not let them demoralize us into not making things better.

[02:51:35.010] - Speaker 2
And so, yeah, I really kind of went to town. I was inspired by a lot of prior manifestos, one in particular that I enjoyed tremendously, which is the futurist manifesto from the italian futurist art movement in the nightmare on 1910. So I don't know that I hit the bar of the futurist manifesto, but that was my sort of inspirational kind of starting point. And, of course, that was an artistic, esthetic movement, not a technological movement, but it was at a time when they were very obsessed with new technologies and what new technologies would mean for art. So hopefully I got a little bit of that flavor in there.

[02:52:05.200] - Speaker 1
When is technology a net negative?

[02:52:07.520] - Speaker 2
Yeah, when it kills a lot of people, basically. When it causes Misery. Right. So, look, fire. I talk in the manifesto, like, all of our. Both optimism and fear of technology is embedded in the myth of Prometheus, who is the God that brought fire down from the mountain to man. Fire is the life giver. Fire is the source of light and heat and cooks food and serves as warmth at night and scares off the wolves, and it allows us to mount defense. Fire is also a means of attack. And you can use fire to burn somebody to death. You can burn down an entire city. You can fire flaming arrows. I've been reading about the history of Middle east stuff, and one of the reasons that they discovered there was oil in the Middle east is because the Arabs of that region were early adopters of napalm. In the mid 18 hundreds, they discovered a way to basically take petrochemical substances and basically make, essentially early napalm with them. So a lot of people died by fire. And, I mean, look, like, what is ammunition? We read about shelling taking place somewhere. They're setting up bombs.

[02:53:10.980] - Speaker 2
Fire is the weapon of a bomb. Fire is the weapon of the catalyst for a bullet fire.

[02:53:16.840] - Speaker 1
It's a huge power source.

[02:53:18.090] - Speaker 2
Fire is. What does a nuclear weapon do? Is it generates fire. Right. And so it's all in there. But the thing is, you can say that basically, it's really easy to. Same thing. I'm drinking water. You can drown in water. You can use a shovel to dig a well. You can use a shovel to club death. It's a tool and I won't go so far as to say tools are value neutral in that they carry consequences with them. And specifically they carry consequences to the ordering of human society, which is ultimately the thing that's being litigated when we talk about all this stuff. But that said, they tend to have both use cases and it is arguably easy to get carried away and just assume that it's only upsides. And I think it's also very easy to get carried away and to say that it's mostly downsides. I think most arguments about technology are not actually arguments about the technology. I think they're arguments about the ordering of society. I think most people opposed to technological change are not actually opposed to the technology per se. They're opposed to what they see as a diminishment of their own status and power.

[02:54:14.310] - Speaker 2
I think that's why the news industry is so anti tech is because they view as a challenge to their own, their traditional gatekeeping role and their historical businesses. Look, is societal change good or bad? It depends, right? We are all very happy we don't live in the societies ordered the way that they were 4000 years ago. That would suck. But is all societal change good? Probably not. We live in a society today where suicides are rising. Well, okay, something's going wrong, right? So what caused that to happen anyway? I think all of the important questions around technology are actually questions about society, which are questions about people. But if we use the fear of societal change and paranoia about technology to prevent progress, I think that leads to stagnation. And I think that creates problems that are almost certainly worse. I'd actually link it to politics. I'd link to politics. And this is not a right wing or left wing observation, but basically what you find is when societies grow they tend to have a positive sum mentality, right, where some people can rise without it being a threat to everybody. Because everybody kind of views that there's opportunity when societies aren't growing.

[02:55:14.160] - Speaker 2
You get zero sum politics, right? For me to get something, I have to take it away from you. And I think what happened basically is our society downshifted to a slower rate of technological development and a slower rate of growth in the 1960s, 1970s. And I think that's culminated in basically zero sum politics both on the american left and on the american right where they've gotten increasingly negative and hostile and kind of destructive. To me, the clear answer to anybody who doesn't like the way politics in the US are going, the clear answer is we need growth. To get growth, we need technology. That is the actual answer, whether people will buy that or not, I don't know.

[02:55:50.100] - Speaker 1
Tell me something you believe most people.

[02:55:52.010] - Speaker 2
Don'T believe technology is good.

[02:55:54.820] - Speaker 1
I don't know. I think a lot of people believe.

[02:55:56.500] - Speaker 2
That that is unfair. So this is another distinction I'd make. I make this a bit in the essay, which is, it's actually not the case to your point, it's not the case that most people are negative on technology. It's the case that most elites are negative on technology right now. And again, I think they're negative on it primarily because they view it as a threat to their power and status as elites. So I would say if the form of the question is, what do you believe that other elites don't believe like that, that would definitely be the answer to that question. Okay, I'll give you one. I'll give you one. I'll give the flip side of it, which is developing new technology is like creating anything else. It is an elite art form. It's an elite process. Not everybody can do it. It's going to be a very small, rarefied group of people who are going to be able to do it.

[02:56:35.000] - Speaker 1
What's the furthest out conspiracy theory that you believe?

[02:56:44.020] - Speaker 2
Conspiracy theory? I don't know if this is a conspiracy theory. I think Jung was right about the collective unconscious. I don't know if that's a conspiracy theory. Maybe that's more just a metaphysical theory or something. I think there's a collective human experience. I have a completely materialist explanation for that, but I don't know. That's limited to the material. I don't know that the material explanation is sufficient.

[02:57:06.200] - Speaker 1
And do you think of yourself as a spiritual person?

[02:57:08.770] - Speaker 2
No. I am a scientist and a technologist all the way through, and I apply the scientific method to everything. But I'm also like, because I read a lot of history, I know that there are very sharp limits to that, to the explanatory power of science and technology. It does not explain most things. It's not, in fact, a general purpose tool. And there is a lot that we. This is what, it's this way. The amount of things we don't know far exceeds the number of things we do know. I mean, look, this is physics. Physics is a field that's, like, totally hung up. They've sort of hit a brick wall 50 years ago. And the rest of the questions of how the reality of the universe is structured and matter and everything else is basically still unknown. And so how much can we actually understand? There's a great book I read at one time, it really struck me called, it's called the half life of facts. It turns out, basically, if you go across time, it turns. So, you know, radioactive material has a half. Half life is the amount of time it takes for half the radiation to fade.

[02:58:02.970] - Speaker 2
So it's like this curve. So this guy basically says, facts have a half life. Like, anything, any given anything human society at the moment believes is a fact is like. And there's different half lives. And he talks about the different models, but it's like, on average, within 50 years, that will no longer be a fact, and we will just be so confident that we will have. Newton for sure thought he had orbital mechanics figured out, and then it turned out, no, relativity was, like, screwing everything up, right? And then Einstein thought he had relativity figured out, and then quantum mechanics came along and just completely freaked him out, right? And so even those guys, it turns out the things that they knew for sure actually turned out not to be right now, by the way, those things that they knew were very useful while they knew them. Right. It's just they weren't actually the underlying truth. And so I guess I would say, yes, I am very open to underlying truths that we don't yet know. Personally, I don't know how to get there spiritually, but I don't want to rule anything out.

[02:58:57.760] - Speaker 1
Where would you say you're the furthest out? On the fringe?

[02:59:06.260] - Speaker 2
I'm not on the fringe at all in my daily life. Like, I have a lot of friends who are very, like, they're super drugs, the whole burning man. I'm not a hallucinogens guy or anything like that. So I don't do, like, helicopter skiing, paragliding. So there's a lot of things that I'm not out on the edge on. I'm very bourgeois personally, but I'm extremely open to new ideas. And particularly, obviously, new technological ideas, new business ideas, new cultural ideas. I'm reflexively default open. And that's just, like, incredibly rare in practice. Quite honestly. Most people, over time, develop scar tissue around new ideas. Most new ideas don't work, right. And so generally, your experience throughout the course of your life is people throwing up new ideas that are actually, like, bad ideas or ideas that don't work. And so generally, as people age, they actually get less open. They get kind of more set in their ways. They have more rules to how they think about things. All of my scar tissue is in the other direction. Ideas that were good, ideas that I thought were bad ideas. And as a consequence, I didn't take seriously enough fast enough.

[03:00:09.350] - Speaker 2
And so my big lesson over time has been, I need to be more open every day that goes by. The lesson the universe teaches me is, you need to be more open minded. And so I'm getting more and more open minded as I get old.

[03:00:19.480] - Speaker 1
Sounds great.

[03:00:20.250] - Speaker 2
It is great. It's great. It's very fun. I know a handful of people who have been able to do that over time at more advanced agents, and I really admire them, and I enjoy it a great deal. It's very fun, and we teach it inside the firm. We're very deliberate about it. But it is weird because it's like I'm on the opposite trajectory of almost everybody of my age cohort.

[03:00:38.940] - Speaker 1
Well, it's a really humble place to be.

[03:00:41.710] - Speaker 2
Yes.

[03:00:43.680] - Speaker 1
You accept that. You don't know.

[03:00:45.470] - Speaker 2
You don't know. Yeah. Look, why on earth do I have the knowledge and insight and predictive capability to be able to say, this idea is a bad idea? And the answer is, I don't. I really, really, genuinely don't. But look, and part of that goes back to the venture thing, 50 50 thing we're talking about. It's like, look, a lot of new ideas are bad ideas, right? A lot of them are actually bad ideas, but that's okay, right? There are going to be a lot of bad ideas. And it is.

[03:01:09.400] - Speaker 1
Can you think of an example of something that was pitched to you that you perceived as a bad idea, that turned into a very good idea that maybe even changed the world?

[03:01:17.160] - Speaker 2
Well, I mean, look, this AI stuff. Look, I was trained on AI. I was trained on all this stuff. Neural networks in the. Was a big AI boom in the. Totally failed. The conclusion from that was, this stuff will never work. I had that conclusion along with everybody. I just kind of took it by default, GPT or whatever. These are big breakthroughs in the last year that are very kind of shocking, even to us, of how well they work. But we knew there was an arc that was playing out. But I will tell you, before 2012, I would not have told you that. I would have said, yeah, no, that field is dead. It's just like, stick a fork in it. Well, here's another thing. Look, I don't know if this is true. Tell me if this is true of art also. Is there a prehistory, is there a prehistory to music where when there's some big breakthrough in music, you can look back after the fact and you can be like, actually, somebody tried that ten or 20 or 30 or 40 years earlier, and they just.

[03:01:59.680] - Speaker 1
It's usually a cycle.

[03:02:00.900] - Speaker 2
Okay?

[03:02:01.500] - Speaker 1
Like, I can remember when grunge happened. It wasn't that exciting to me because when I was younger, I got to experience Aerosmith, right? And Aerosmith was my generation's version of the Rolling Stones, right? So if you were alive in the stones, were it, and then if you were a kid in the late seventy s, it was Aerosmith. But then in the 80s, late eighty s, it was nirvana.

[03:02:32.090] - Speaker 2
Right?

[03:02:32.470] - Speaker 1
But it was all the same thing coming back around again.

[03:02:36.920] - Speaker 2
Okay, and what would have been the origin point? Was it Delta blues or something even older than that?

[03:02:43.130] - Speaker 1
Yes, but I don't even know if you could say there's an origin, because it probably goes back to indigenous music. There's always been music. It's always building off something from the past and changing and finding a new way or a new piece of technology comes along, or a new instrument comes along, and that changes everything.

[03:03:06.720] - Speaker 2
So I think with what we do, I think there's more of a material component to it, which is there are certain things that are just not possible until they're possible. And so there are discontinuous breaks, like the story of Charles Babbage. Like, he couldn't build a difference machine. He didn't have the technology of the technology at the time, did not permit it. It was not possible for him to do that. But by the 1930s, 1940s, it was possible. So there are discontinuous changes in our world that are based on just material limitations. Having said that, almost everything that works in tech, people have been trying to get it to work for decades before it actually works. Right? And so even, like, Chat GPT, there was a chat system called Eliza in the 1950s where they tried to basically get this to work. Eliza actually passes the Turing test for a. A lot lot people of. Of people. A lot of people actually think Eliza is a real person as, like, a psychiatrist bot. And so people have been trying to get those things to work for a long time. Or, like, the Internet. Look, the Internet has a prehistory that goes back to the 1950s, when a lot of the original work on what's called packet switching was first done.

[03:03:58.530] - Speaker 2
That didn't really take off until the other thing that I'm just really open to is. And where history else is very helpful is just like, if something is working, if there's, like, a breakthrough that's working today, it almost certainly, in tech is not just like a brand new thing. It's probably something where there's a 40 year backstory. Yeah, exactly. And there are probably generations of scientists and technologists and founders who tried and failed. There's tons of examples in this, but one of my favorite ones is the French had optical telegraphs working, like, 40 years before. Electric telegraphs. They had a system of glass tubes with flashing lights under the streets of Paris, and they could flash messages across long distances. And they had, like, mirrors and repeaters and all kinds of stuff. And it was just, like, in the 1840s or something.

[03:04:41.840] - Speaker 1
Wow.

[03:04:42.400] - Speaker 2
Right? And so it's like, all right, because the telegraph takes off 30 or 40 years later. It's like, okay, was that a breakthrough idea, or was that just like, the 40 year version of, oh, television? Television is a great example. There was a scottish inventor who invented mechanical television starting in, like, the 1890s, and he had a system where it would actually receive radio waves, but it was a mechanical television. So there was no tube or electronics or anything. It was entirely mechanical. It was spinning wooden blocks in a grid, and the blocks had different colors and different sides, and the blocks would spin to represent, like, red, green, or blue. And apparently the accounts of time is like, if you squinted, you could actually see the picture coming through.

[03:05:19.730] - Speaker 1
Wow.

[03:05:20.370] - Speaker 2
But it took another 30 years before you had black and white television after that. So there's this deep level, not always, at least in our societies, societies we've been lucky enough to live in, there's always some reservoir of fringe thinkers who are, like, way out there on the leading edge, probably decades ahead of their time, probably are never going to be remembered, probably actually originate the ideas. Then they kind of put the ideas.

[03:05:45.630] - Speaker 1
In the air, and then ten years, 2030 years later, someone finds a way to execute it.

[03:05:53.430] - Speaker 2
That's right. Well, as I said, even neural networks, as I said, I was actually shocked to learn this. I was reconstructing the history of AI last year, and I thought the debate started in the 40s, actually started in the 30s, about whether you could build computers based on the human brain. How much did they know about the brain in the 1930s? Like, it couldn't have been that much, but they knew enough to immediately think like, wow, here's what we could do. To me, those are the people I really. To be that far ahead of your time and. Right.

[03:06:24.080] - Speaker 1
It's just like, wow, amazing. How does Moore's law continue to.

[03:06:32.240] - Speaker 2
The.

[03:06:32.900] - Speaker 1
We never get to the end.

[03:06:34.210] - Speaker 2
No, you get to the end. Well, there's huge debate around this. You're down to what's called two nanometer transistors. And so we're down to the level of manufacturing that's taking place the incredible leaps. If you ever get a chance. There's this company, I think, called Applied Materials, that's the dutch company that makes the equipment to manufacture modern microchips. And it's these giant rooms. It's this incredibly elaborate machinery. And it's doing all these things, a lot of us, with photolithography. So it's literally shining patterns with light to manufacture things that end up being material. And then it's these manufacturing processes. 2 nm fractions of tiny, tiny, tiny fractions of a human hair. Stuff as like the atomic level. Like a lot of the barriers for progress of Moore's law, literally, is we're getting down to the level of individual atoms. And the problem is we can't subdivide the atoms without blowing everything up.

[03:07:23.840] - Speaker 1
It's unbelievable.

[03:07:24.780] - Speaker 2
And so, yeah, it's like manufacturing at the atomic level. There's huge amounts of engineering going into trying to optimize that. There's a lot of work going into trying to make like ships three dimensional. Right. So it's not taken up another dimension. What else? There's a lot of work going into so called quantum computers, which is a totally different architecture design, which in theory is going to be another one of these huge breakthroughs that just works totally differently, by the way, there's a lot of work going into biological computers. So there's people working on storage. It turns out you can store huge amounts of data in DNA because the human body encodes enormous amounts of information.

[03:07:56.510] - Speaker 1
Wow, that's really cool.

[03:07:57.570] - Speaker 2
Cellular level. And so there's people working on that. There's people working on biological computers, growing computers in tanks.

[03:08:03.510] - Speaker 1
Wow, so cool.

[03:08:06.010] - Speaker 2
Yeah, there's a whole field of information processing that all this stuff is based on, which is like what babbage and loveless and these guys people came up with. And it's sort. Yeah, the pattern is like how to store, manipulate, analyze, synthesize large amounts of information. And it just turns out that the payoff from being able to do that is just gigantic. And so the amount of money that you would spend on R and D, to be able to figure out better ways to do that is effectively unbounded.

[03:08:28.770] - Speaker 1
Amazing.

[03:08:29.270] - Speaker 2
And that continues.
